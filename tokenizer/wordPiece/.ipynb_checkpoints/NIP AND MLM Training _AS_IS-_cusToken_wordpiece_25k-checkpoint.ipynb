{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import sys,os\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from elftools.elf.segments import Segment\n",
    "from capstone import *\n",
    "from capstone.x86 import *\n",
    "\n",
    "import os\n",
    "import json \n",
    "\n",
    "import sys,os\n",
    "device = 'cuda:2' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MAX_TOKEN_LEN = 512\n",
    "BATCH_SIZE = 64\n",
    "EXPERIMENT_NAME = 'cusTokenizer_WP_25k_ASIS'\n",
    "\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction,BertForPreTraining\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"./../../models/\" + EXPERIMENT_NAME)\n",
    "print(tokenizer.pad_token) \n",
    "# model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "model = BertForPreTraining.from_pretrained('bert-base-uncased')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81107\n",
      "Functions Count:  81107 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "DATA_PATH = '/home/raisul/ANALYSED_DATA/tokenization_data_single_functions'\n",
    "\n",
    "TRAIN_DATA_PATH  ='/home/raisul/ANALYSED_DATA/tokenization_data_single_functions/train/'\n",
    "\n",
    "TEST_DATA_PATH   = '/home/raisul/ANALYSED_DATA/tokenization_data_single_functions/test/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_json_files = [os.path.join(TRAIN_DATA_PATH, f) for f in os.listdir(TRAIN_DATA_PATH) ]\n",
    "\n",
    "test_json_files = [os.path.join(TEST_DATA_PATH, f) for f in os.listdir(TEST_DATA_PATH) ]\n",
    "\n",
    "# disassembly_decimal disassembly_all_number_to_words disassembly_decimal\n",
    "data_key = \"disassembly_decimal\"\n",
    "\n",
    "print(len(train_json_files))\n",
    "def read_corpus(json_files):\n",
    "\n",
    "    all = []\n",
    "\n",
    "    for k, j_file in enumerate(json_files):\n",
    "        # if k>200:\n",
    "        #     break\n",
    "        try:\n",
    "\n",
    "            with open(j_file, 'r') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                funct = data[data_key]['input']\n",
    "                \n",
    "                all.append(funct)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    return all\n",
    "    \n",
    "\n",
    "\n",
    "train_text = read_corpus(train_json_files)\n",
    "test_text  = read_corpus(test_json_files)\n",
    "\n",
    "\n",
    "        \n",
    "# text = text[0:5000]\n",
    "print(\"Functions Count: \",len(train_text), '\\n')\n",
    "example = train_text[10]\n",
    "text = train_text + test_text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDBR64\n",
      "SUB RSP,24\n",
      "LEA RSI,[8196]\n",
      "MOV EDI,2\n",
      "MOV RAX,qword ptr FS:[40]\n",
      "MOV qword ptr [RSP + 8],RAX\n",
      "XOR EAX,EAX\n",
      "CALL 4224\n",
      "LEA RSI,[RSP + 4]\n",
      "LEA RDI,[8221]\n",
      "XOR EAX,EAX\n",
      "CALL 4240\n",
      "MOV EAX,dword ptr [RSP + 4]\n",
      "MOV EDI,2\n",
      "LEA RSI,[8220]\n",
      "IMUL EDX,EAX,111\n",
      "LEA ECX,[RAX + RAX*2]\n",
      "IMUL EAX,EAX,1111\n",
      "LEA EDX,[RDX + RCX*4]\n",
      "ADD EDX,EAX\n",
      "XOR EAX,EAX\n",
      "CALL 4224\n",
      "MOV RAX,qword ptr [RSP + 8]\n",
      "SUB RAX,qword ptr FS:[40]\n",
      "JNZ 4379\n",
      "XOR EAX,EAX\n",
      "ADD RSP,24\n",
      "RET\n",
      "CALL 4208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text[51].split(delim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll assign a 50% probability of using the genuine next sentence, and 50% probability of using another random sentence.\n",
    "\n",
    "To make this simpler, we'll create a *'bag'* of individual sentences to pull from when selecting a random sentence B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2896720 101107\n"
     ]
    }
   ],
   "source": [
    "delim = '\\n'\n",
    "bag = [instruction for instruction_cluster in text for instruction in instruction_cluster.split(delim)  if instruction!= '']\n",
    "bag_size = len(bag)\n",
    "print(bag_size , len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we create our 50/50 NIP training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101107\n",
      "['ENDBR64', 'PUSH R12', 'LEA RSI,[8200]', 'MOV EDI,2', 'PUSH RBP', 'PUSH RBX', 'SUB RSP,32', 'MOV RAX,qword ptr FS:[40]', 'MOV qword ptr [RSP + 24],RAX', 'XOR EAX,EAX', 'CALL 4224', 'LEA RCX,[RSP + 16]', 'LEA RDX,[RSP + 12]', 'XOR EAX,EAX', 'LEA RSI,[RSP + 8]', 'LEA R8,[RSP + 20]', 'LEA RDI,[8246]', 'CALL 4240', 'MOV EBX,dword ptr [RSP + 20]', 'MOV R12D,dword ptr [RSP + 12]', 'LEA RSI,[8258]', 'MOV EBP,dword ptr [RSP + 8]', 'MOV EAX,dword ptr [RSP + 16]', 'MOV EDI,2', 'IMUL EBP,EBX', 'IMUL EAX,R12D', 'IMUL EBX,R12D', 'ADD EBP,EAX', 'XOR EAX,EAX', 'CALL 4224', 'XOR EAX,EAX', 'MOV ECX,EBX', 'MOV EDX,EBP', 'LEA RSI,[8252]', 'MOV EDI,2', 'CALL 4224', 'MOV RAX,qword ptr [RSP + 24]', 'SUB RAX,qword ptr FS:[40]', 'JNZ 4434', 'ADD RSP,32', 'XOR EAX,EAX', 'POP RBX', 'POP RBP', 'POP R12', 'RET', 'CALL 4208']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "history = []\n",
    "next_instruction = []\n",
    "label = []\n",
    "\n",
    "\n",
    "instruction_pages = []\n",
    "for instruction_cluster in text:\n",
    "    instructions = [\n",
    "        instruction for instruction in instruction_cluster.split(delim) if instruction != ''\n",
    "    ]\n",
    "\n",
    "    instruction_pages.append(instructions)\n",
    "    # if len(instructions)>page_len:\n",
    "        \n",
    "    #     for i in range(0,len(instructions),page_len):\n",
    "    #         instruction_pages.append(instructions[i:i+page_len])\n",
    "        \n",
    "print(len(instruction_pages))\n",
    "print(instruction_pages[0])\n",
    "\n",
    "for instruction_page in instruction_pages:\n",
    "    \n",
    "#     instructions = [\n",
    "#         instruction for instruction in instruction_page.split(';') if instruction != ''\n",
    "#     ]\n",
    "    \n",
    "    \n",
    "#     num_instructions = len(instruction_page)\n",
    "    \n",
    "    \n",
    "\n",
    "#     start = random.randint(0, num_instructions-2)\n",
    "    # 50/50 whether is IsNextSentence or NotNextSentence\n",
    "    if random.random() >= 0.5:\n",
    "        # this is IsNextSentence\n",
    "        history.append(delim.join(instruction_page[:-1]))\n",
    "        next_instruction.append(instruction_page[-1])\n",
    "        label.append(0)\n",
    "    else:\n",
    "        index = random.randint(0, bag_size-1)\n",
    "        # this is NotNextSentence\n",
    "        history.append(delim.join(instruction_page[:-1]))\n",
    "        next_instruction.append(bag[index])\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101107\n",
      "0\n",
      "-> ENDBR64\n",
      "PUSH R12\n",
      "LEA RSI,[8200]\n",
      "MOV EDI,2\n",
      "PUSH RBP\n",
      "PUSH RBX\n",
      "SUB RSP,32\n",
      "MOV RAX,qword ptr FS:[40]\n",
      "MOV qword ptr [RSP + 24],RAX\n",
      "XOR EAX,EAX\n",
      "CALL 4224\n",
      "LEA RCX,[RSP + 16]\n",
      "LEA RDX,[RSP + 12]\n",
      "XOR EAX,EAX\n",
      "LEA RSI,[RSP + 8]\n",
      "LEA R8,[RSP + 20]\n",
      "LEA RDI,[8246]\n",
      "CALL 4240\n",
      "MOV EBX,dword ptr [RSP + 20]\n",
      "MOV R12D,dword ptr [RSP + 12]\n",
      "LEA RSI,[8258]\n",
      "MOV EBP,dword ptr [RSP + 8]\n",
      "MOV EAX,dword ptr [RSP + 16]\n",
      "MOV EDI,2\n",
      "IMUL EBP,EBX\n",
      "IMUL EAX,R12D\n",
      "IMUL EBX,R12D\n",
      "ADD EBP,EAX\n",
      "XOR EAX,EAX\n",
      "CALL 4224\n",
      "XOR EAX,EAX\n",
      "MOV ECX,EBX\n",
      "MOV EDX,EBP\n",
      "LEA RSI,[8252]\n",
      "MOV EDI,2\n",
      "CALL 4224\n",
      "MOV RAX,qword ptr [RSP + 24]\n",
      "SUB RAX,qword ptr FS:[40]\n",
      "JNZ 4434\n",
      "ADD RSP,32\n",
      "XOR EAX,EAX\n",
      "POP RBX\n",
      "POP RBP\n",
      "POP R12\n",
      "RET \n",
      "\n",
      "#  CALL 4208 \n",
      "\n",
      "0\n",
      "-> ENDBR64\n",
      "MOV EAX,dword ptr [16448]\n",
      "LEA RCX,[16480]\n",
      "LEA EDX,[RAX + 1]\n",
      "ADD EAX,2\n",
      "MOVSXD RSI,EDX\n",
      "MOV dword ptr [16448],EDX\n",
      "MOV dword ptr [RCX + RSI*4],EDI\n",
      "CMP EAX,2\n",
      "JA 4839\n",
      "RET\n",
      "MOVSXD RDX,EDX\n",
      "MOV dword ptr [RCX + RSI*4],EDI\n",
      "MOV dword ptr [RCX + RDX*4],R8D\n",
      "LEA EDX,[RAX + 1]\n",
      "CMP EDX,2\n",
      "JBE 4860\n",
      "MOV EDI,dword ptr [RCX + RSI*4]\n",
      "MOV EDX,EAX\n",
      "MOV EAX,EDX\n",
      "SHR EAX,31\n",
      "ADD EAX,EDX\n",
      "SAR EAX,1\n",
      "MOVSXD RSI,EAX\n",
      "MOV R8D,dword ptr [RCX + RSI*4]\n",
      "CMP R8D,EDI\n",
      "JL 4816 \n",
      "\n",
      "#  RET \n",
      "\n",
      "1\n",
      "-> ENDBR64\n",
      "PUSH RBP\n",
      "LEA RBP,[8231]\n",
      "XOR EAX,EAX\n",
      "MOV ESI,2\n",
      "PUSH RBX\n",
      "MOV RDI,RBP\n",
      "SUB RSP,8\n",
      "CALL 4384\n",
      "TEST EAX,EAX\n",
      "JS 4499\n",
      "MOV EBX,EAX\n",
      "MOV RDX,RBP\n",
      "MOV EDI,2\n",
      "XOR EAX,EAX\n",
      "LEA RSI,[8267]\n",
      "CALL 4368\n",
      "MOV EDI,EBX\n",
      "CALL 4784\n",
      "MOV EDI,EBX\n",
      "CALL 4352\n",
      "XOR EAX,EAX\n",
      "ADD RSP,8\n",
      "POP RBX\n",
      "POP RBP\n",
      "RET\n",
      "CALL 4288\n",
      "MOV EDI,dword ptr [RAX]\n",
      "CALL 4400\n",
      "LEA RSI,[8253]\n",
      "MOV EDI,2\n",
      "MOV RDX,RAX\n",
      "XOR EAX,EAX\n",
      "CALL 4368\n",
      "OR EAX,4294967295 \n",
      "\n",
      "#  MOV dword ptr [16416],0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(label))\n",
    "for i in range(3):\n",
    "    print(label[i])\n",
    "    print('->',history[i] , '\\n')\n",
    "    print('# ',next_instruction[i] , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now ready for tokenization, this time we truncate/pad each token to the same length of *512* tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(history, next_instruction, return_tensors='pt', \n",
    "                   max_length=MAX_TOKEN_LEN, truncation=True, padding=True)\n",
    "ground_truth = inputs.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the *token_type_ids* tensors have been built correctly (eg **1** indicating sentence B tokens) by checking the first instance of *token_type_ids*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([101107, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs.input_ids.shape)\n",
    "inputs.token_type_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **0** tokens following our sentence B tokens correspond to *PAD* tokens.\n",
    "\n",
    "Alongside this, we need to create a *labels* tensor too - which corresponds to the values contained within our `label` variable. Our *labels* tensor must be a *LongTensor*, and we will need to transpose the tensor so that it matches our other tensors' dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the labels tensor is simply a clone of the input_ids tensor before masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    3,    69,   105,    17,   101,    74,    21,    16,    12,    11,\n",
       "            7,     8,     6,    10,     9,     7,    45,    29,     6,    16,\n",
       "           12,    11,     7,     8,     6,    10,     9,     7,    22,     6,\n",
       "           13,    75,    18,    33,    14,    15,    71,    17,    65,    47,\n",
       "            6,    13,    78,    17,  1534,    18,    33,    14,    15,    90,\n",
       "           48,     8,    12,    11,     7,     8,     6,    10,     9,     7,\n",
       "           22,     6,    13,   107,    41,    17,  2260,   103,    89,    46,\n",
       "           24,  4061,  1944,  2303,   290,     6,    13,   860,   103,    89,\n",
       "         9132, 16364,   163,    46,   302,     6,    13,   556,    31,   138,\n",
       "           18,    33,    14,    15,    84,    21,    16,    12,    11,     7,\n",
       "            8,     6,    10,     9,     7,    22,     6,    13,    88,    21,\n",
       "           16,    12,    11,     7,     8,     6,    10,     9,     7,    68,\n",
       "           43,    19,  1808,    18,    60,   105,   642,    26,     4,     6,\n",
       "           23,   110,  1898,     4,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "            2,     2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we mask tokens in the input_ids tensor using the 15% probability for MLM - ensuring we don't mask CLS, SEP, or PAD tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([101107, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr.shape\n",
    "# inputs.input_ids.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now take the indices of each True value within each vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101107,\n",
       " 101107,\n",
       " [[2,\n",
       "   7,\n",
       "   17,\n",
       "   23,\n",
       "   24,\n",
       "   30,\n",
       "   32,\n",
       "   35,\n",
       "   43,\n",
       "   49,\n",
       "   52,\n",
       "   53,\n",
       "   66,\n",
       "   69,\n",
       "   73,\n",
       "   83,\n",
       "   90,\n",
       "   93,\n",
       "   98,\n",
       "   100,\n",
       "   108,\n",
       "   109,\n",
       "   126,\n",
       "   127,\n",
       "   131,\n",
       "   133,\n",
       "   134,\n",
       "   136,\n",
       "   144,\n",
       "   155,\n",
       "   159,\n",
       "   161,\n",
       "   164,\n",
       "   165,\n",
       "   236,\n",
       "   248,\n",
       "   249,\n",
       "   254,\n",
       "   268,\n",
       "   271,\n",
       "   274,\n",
       "   281,\n",
       "   287,\n",
       "   290,\n",
       "   295,\n",
       "   298,\n",
       "   304,\n",
       "   306,\n",
       "   307,\n",
       "   309,\n",
       "   314,\n",
       "   324,\n",
       "   325,\n",
       "   339,\n",
       "   342,\n",
       "   347,\n",
       "   354,\n",
       "   355,\n",
       "   358,\n",
       "   379,\n",
       "   385,\n",
       "   389,\n",
       "   398,\n",
       "   404,\n",
       "   419,\n",
       "   424,\n",
       "   429,\n",
       "   434,\n",
       "   437,\n",
       "   442,\n",
       "   444,\n",
       "   446,\n",
       "   448,\n",
       "   450,\n",
       "   457,\n",
       "   462,\n",
       "   490,\n",
       "   494,\n",
       "   506,\n",
       "   507,\n",
       "   508],\n",
       "  [6,\n",
       "   8,\n",
       "   27,\n",
       "   29,\n",
       "   34,\n",
       "   35,\n",
       "   55,\n",
       "   63,\n",
       "   66,\n",
       "   75,\n",
       "   78,\n",
       "   92,\n",
       "   101,\n",
       "   106,\n",
       "   110,\n",
       "   118,\n",
       "   135,\n",
       "   145,\n",
       "   147,\n",
       "   151,\n",
       "   157,\n",
       "   185,\n",
       "   196,\n",
       "   203,\n",
       "   204,\n",
       "   208,\n",
       "   215,\n",
       "   218,\n",
       "   225,\n",
       "   246,\n",
       "   252,\n",
       "   264,\n",
       "   265,\n",
       "   267,\n",
       "   271,\n",
       "   284,\n",
       "   292,\n",
       "   293,\n",
       "   294,\n",
       "   318,\n",
       "   320,\n",
       "   322,\n",
       "   328,\n",
       "   335,\n",
       "   339,\n",
       "   341,\n",
       "   342,\n",
       "   355,\n",
       "   356,\n",
       "   379,\n",
       "   383,\n",
       "   388,\n",
       "   428,\n",
       "   435,\n",
       "   444,\n",
       "   452,\n",
       "   455,\n",
       "   460,\n",
       "   468,\n",
       "   476,\n",
       "   477,\n",
       "   482,\n",
       "   486,\n",
       "   493,\n",
       "   496,\n",
       "   499,\n",
       "   501,\n",
       "   504,\n",
       "   506,\n",
       "   510,\n",
       "   511],\n",
       "  [5,\n",
       "   10,\n",
       "   14,\n",
       "   15,\n",
       "   48,\n",
       "   49,\n",
       "   50,\n",
       "   65,\n",
       "   67,\n",
       "   69,\n",
       "   70,\n",
       "   79,\n",
       "   80,\n",
       "   83,\n",
       "   91,\n",
       "   99,\n",
       "   102,\n",
       "   103,\n",
       "   106,\n",
       "   107,\n",
       "   111,\n",
       "   112,\n",
       "   116,\n",
       "   143,\n",
       "   146,\n",
       "   148,\n",
       "   151,\n",
       "   158,\n",
       "   173,\n",
       "   176,\n",
       "   178,\n",
       "   179,\n",
       "   183,\n",
       "   194,\n",
       "   199,\n",
       "   223,\n",
       "   236,\n",
       "   237,\n",
       "   238,\n",
       "   240,\n",
       "   246,\n",
       "   253,\n",
       "   261,\n",
       "   264,\n",
       "   270,\n",
       "   289,\n",
       "   291,\n",
       "   298,\n",
       "   304,\n",
       "   312,\n",
       "   317,\n",
       "   320,\n",
       "   327,\n",
       "   329,\n",
       "   347,\n",
       "   352,\n",
       "   356,\n",
       "   365,\n",
       "   370,\n",
       "   371,\n",
       "   372,\n",
       "   376,\n",
       "   381,\n",
       "   388,\n",
       "   390,\n",
       "   391,\n",
       "   393,\n",
       "   396,\n",
       "   401,\n",
       "   410,\n",
       "   413,\n",
       "   425,\n",
       "   450,\n",
       "   461,\n",
       "   463,\n",
       "   482,\n",
       "   500,\n",
       "   501,\n",
       "   505,\n",
       "   509]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (selection) , len(inputs.input_ids), selection[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then apply these indices to each row in input_ids, assigning each value at these indices a value of 103."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  20,   20,    8,   29,    6,    6,    9,    6,   17,   17,    6,   13,\n",
       "          13, 2234,   90,    7,   12,    8,   22,   13,    7,    8,    9,    7,\n",
       "         160,   89, 2687,   89,   33,   76,   21,   12,    8,    6,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[0][selection[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_labels = []\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    masked_labels.append(inputs.input_ids[i, selection[i]])\n",
    "    inputs.input_ids[i, selection[i]] = 103\n",
    "# masked_labels[0]\n",
    "inputs[\"mask_arr\"] = mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels', 'mask_arr'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `inputs` tensors are now ready, and we can begin building the model input pipeline for training. We first create a PyTorch dataset from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeditationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize our data using the `MeditationDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MeditationsDataset(inputs)\n",
    "# print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101107\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 81107) range(81107, 101107)\n"
     ]
    }
   ],
   "source": [
    "print( range(len(train_text)), range(len(train_text) , len(dataset)  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81107, 20000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data_portion =  len(train_text)/(len(train_text) + len( test_text) )\n",
    "# print(train_data_portion ,(len(train_text) + len( test_text) ))\n",
    "\n",
    "# train_size = int(train_data_portion * len(dataset))\n",
    "# validation_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset  = torch.utils.data.Subset(dataset, range(len(train_text)))\n",
    "validation_dataset = torch.utils.data.Subset(dataset, range(len(train_text) , len(dataset)))\n",
    "\n",
    "len(train_dataset) , len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And initialize the dataloader, which we'll be using to load our data into the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto setting up the training loop. First we setup GPU/CPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the training mode of our model, and initialize our optimizer (Adam with weighted decay - reduces chance of overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto the training loop, we'll train for a couple of epochs (change `epochs` to modify this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odict_keys(['loss', 'prediction_logits', 'seq_relationship_logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graph(training_data, validation_data , label ):\n",
    "\n",
    "    font_size = 10\n",
    "    x_labels = [ i for i in range(len(training_data)) ]\n",
    "\n",
    "    plt.ylabel(' F1 ',fontsize=font_size)\n",
    "    plt.plot(x_labels, training_data , 'r') \n",
    "    plt.plot(x_labels, validation_data , 'b') \n",
    "    plt.xlabel(\"Epoch\", fontsize=font_size)\n",
    "    plt.title(label,fontsize=font_size)\n",
    "    plt.legend(['Training', 'Validation'], loc='upper left') \n",
    "    \n",
    "    plt.savefig('./../../results/'+EXPERIMENT_NAME+label+'.pdf')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|                                                  | 0/1268 [00:00<?, ?it/s]/tmp/ipykernel_3622467/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|███████████████████| 1268/1268 [25:21<00:00,  1.20s/it, loss=1.46]\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   Instruction f1:  0.7121389318544787   Masked Token f1 0.6679999104917004     SEQ F1 0.6820265966867898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/313 [00:00<?, ?it/s]/tmp/ipykernel_3622467/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "100%|█████████████████████████████████████████| 313/313 [02:19<00:00,  2.25it/s]\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  Instruction F1:  0.9127681089999468    v_masked_token_ F1:  0.7400558551087372  V SEQ F1:  0.7725897504165433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-15 18:30:25,646] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raisul/anaconda3/envs/pytorch/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/raisul/anaconda3/envs/pytorch/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "  0%|                                                  | 0/1268 [00:00<?, ?it/s]/tmp/ipykernel_3622467/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 1:  45%|█████████           | 576/1268 [11:27<13:52,  1.20s/it, loss=1.27]"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "from itertools import chain\n",
    "\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=5e-6)\n",
    "\n",
    "\n",
    "\n",
    "epochs =100\n",
    "counter = 0\n",
    "\n",
    "global_instruction_metrices = []\n",
    "global_masked_token_metrices = []\n",
    "\n",
    "v_global_instruction_metrices = []\n",
    "v_global_masked_token_metrices = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    train_loop = tqdm(train_loader, leave=True)\n",
    "    \n",
    "    \n",
    "    instruction_predictions_all, instruction_ground_truths_all = None, None\n",
    "    masked_token_predictions_all, masked_token_ground_truths_all = None, None\n",
    "    seq_predictions_all, seq_ground_truths_all = None, None\n",
    "    \n",
    "    # activate training mode\n",
    "    model.train()\n",
    "    for N,batch in enumerate(train_loop):\n",
    "\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        next_sentence_label = batch['next_sentence_label'].to(device)\n",
    "        batch_mask_arr = batch ['mask_arr']\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        next_sentence_label=next_sentence_label,\n",
    "                        labels=labels)\n",
    "\n",
    "\n",
    "        token_prediction = torch.argmax(outputs.prediction_logits, axis=-1)\n",
    "       \n",
    "\n",
    "\n",
    "        # batch_masks = selection [BATCH_SIZE*N : (BATCH_SIZE*(N+1))]\n",
    "        # print('batch_masks old: ',batch_masks)\n",
    "\n",
    "        # print(batch ['mask_arr'].shape) #torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        batch_masks =   [ torch.flatten(bm.nonzero()).tolist()  for bm in batch_mask_arr]    # torch.flatten(batch ['mask_arr'].nonzero()).tolist()\n",
    "        # print('batch_masks new: ',batch_masks)\n",
    "        \n",
    "        # print(\"BATCH_SIZE*N : (BATCH_SIZE*(N+1)): \",BATCH_SIZE*N , (BATCH_SIZE*(N+1)) )\n",
    "        # print(\"batch_masks:\",batch_masks)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        masked_token_prediction = [ token[batch_masks[t]].tolist() for t,token in enumerate(token_prediction) ]\n",
    "        masked_token_prediction = list(chain.from_iterable(masked_token_prediction))\n",
    "        \n",
    "        masked_token_ground_truth   = [ token[batch_masks[t]].tolist() for t,token in enumerate(labels) ]\n",
    "        masked_token_ground_truth = list(chain.from_iterable(masked_token_ground_truth))\n",
    "        \n",
    "\n",
    "        # print(token_prediction , token_ground_truth)\n",
    "\n",
    "        # token_prediction = token_prediction.detach().cpu().numpy().flatten()\n",
    "        # token_ground_truth = labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "        # print(\"token_prediction  : \", token_prediction)\n",
    "        # print(\"token_ground_truth: \", token_ground_truth)\n",
    "\n",
    "\n",
    "        seq_predictions   = token_prediction.detach().cpu().numpy().flatten()\n",
    "        seq_ground_truths = labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "        \n",
    "        instruction_prediction = torch.argmax(outputs.seq_relationship_logits, axis=-1)\n",
    "        instruction_prediction   = instruction_prediction.detach().cpu().numpy().flatten()\n",
    "        instruction_ground_truth = next_sentence_label.detach().cpu().numpy().flatten()\n",
    "        \n",
    "        if N==0:\n",
    "            instruction_predictions_all   = instruction_prediction\n",
    "            instruction_ground_truths_all = instruction_ground_truth\n",
    "            \n",
    "            masked_token_predictions_all         = masked_token_prediction\n",
    "            masked_token_ground_truths_all       = masked_token_ground_truth  \n",
    "\n",
    "\n",
    "            seq_predictions_all = seq_predictions\n",
    "            seq_ground_truths_all = seq_ground_truths\n",
    "            \n",
    "        else:\n",
    "            instruction_predictions_all   = np.concatenate((instruction_predictions_all, instruction_prediction))\n",
    "            instruction_ground_truths_all = np.concatenate((instruction_ground_truths_all, instruction_ground_truth))\n",
    "            \n",
    "            masked_token_predictions_all   = np.concatenate((masked_token_predictions_all, masked_token_prediction))\n",
    "            masked_token_ground_truths_all = np.concatenate((masked_token_ground_truths_all, masked_token_ground_truth))\n",
    "\n",
    "            seq_predictions_all = np.concatenate((seq_predictions_all, seq_predictions))\n",
    "            seq_ground_truths_all = np.concatenate((seq_ground_truths_all, seq_ground_truths))\n",
    "            \n",
    "\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        train_loop.set_description(f'Epoch {epoch}')\n",
    "        train_loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    \n",
    "    instruction_accuracy = (accuracy_score(instruction_ground_truths_all,instruction_predictions_all))\n",
    "    instruction_precision, instruction_recall, instruction_f1, _ = precision_recall_fscore_support(instruction_ground_truths_all,instruction_predictions_all, average='binary')\n",
    "    \n",
    "    masked_token_accuracy = (accuracy_score(masked_token_ground_truths_all, masked_token_predictions_all))\n",
    "    masked_token_precision, masked_token_recall, masked_token_f1, _ = precision_recall_fscore_support(masked_token_ground_truths_all,masked_token_predictions_all,average='weighted')\n",
    "\n",
    "    seq_precision, seq_recall, seq_f1, _ = precision_recall_fscore_support(seq_ground_truths_all,seq_predictions_all,average='weighted')\n",
    "    \n",
    "    print(\"Training: \",  ' Instruction f1: ', instruction_f1 , '  Masked Token f1',masked_token_f1 , \"    SEQ F1\",seq_f1)\n",
    "    global_instruction_metrices.append(instruction_f1)\n",
    "    global_masked_token_metrices.append( masked_token_f1) \n",
    "\n",
    "    ###########################################\n",
    "    ###############  EVAL Validation  #########\n",
    "    ###########################################\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "#         v_predictions_all, v_ground_truths_all = None, None\n",
    "        \n",
    "        v_instruction_predictions_all, v_instruction_ground_truths_all = None, None\n",
    "        v_masked_token_predictions_all, v_masked_token_ground_truths_all = None, None\n",
    "        v_seq_predictions_all, v_seq_ground_truths_all = None, None\n",
    "    \n",
    "    \n",
    "        validation_loop = tqdm(validation_loader, leave=True)\n",
    "        for N,v_batch in enumerate(validation_loop):\n",
    "            \n",
    "            \n",
    "            \n",
    "            v_input_ids = v_batch['input_ids'].to(device)\n",
    "            v_token_type_ids = v_batch['token_type_ids'].to(device)\n",
    "            v_attention_mask = v_batch['attention_mask'].to(device)\n",
    "            v_next_sentence_label = v_batch['next_sentence_label'].to(device)\n",
    "            v_mask_arr = v_batch ['mask_arr']\n",
    "            v_labels = v_batch['labels'].to(device)\n",
    "            # process\n",
    "            v_outputs = model(v_input_ids, attention_mask=v_attention_mask,\n",
    "                            token_type_ids=v_token_type_ids,\n",
    "                            next_sentence_label=v_next_sentence_label,\n",
    "                            labels=v_labels)\n",
    "        \n",
    "            v_token_prediction = torch.argmax(v_outputs.prediction_logits, axis=-1)\n",
    "\n",
    "                    \n",
    "\n",
    "            v_batch_masks =   [ torch.flatten(bm.nonzero()).tolist()  for bm in v_mask_arr]\n",
    "            \n",
    "            v_masked_token_prediction = [ token[v_batch_masks[t]].tolist() for t,token in enumerate(v_token_prediction) ]\n",
    "            v_masked_token_prediction = list(chain.from_iterable(v_masked_token_prediction))\n",
    "            \n",
    "            v_masked_token_ground_truth   = [ token[v_batch_masks[t]].tolist() for t,token in enumerate(v_labels) ]\n",
    "            v_masked_token_ground_truth = list(chain.from_iterable(v_masked_token_ground_truth))\n",
    "    \n",
    "            \n",
    "            \n",
    "\n",
    "            v_seq_prediction = v_token_prediction.detach().cpu().numpy().flatten()\n",
    "            v_seq_ground_truth = v_labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            # token_prediction = [ token[batch_masks[t]].tolist() for t,token in enumerate(token_prediction) ]\n",
    "            # token_prediction = list(chain.from_iterable(token_prediction))\n",
    "            \n",
    "            # token_ground_truth   = [ token[batch_masks[t]].tolist() for t,token in enumerate(labels) ]\n",
    "            # token_ground_truth = list(chain.from_iterable(token_ground_truth))\n",
    "\n",
    "            \n",
    "            v_instruction_prediction = torch.argmax(v_outputs.seq_relationship_logits, axis=-1)\n",
    "            v_instruction_prediction   = v_instruction_prediction.detach().cpu().numpy().flatten()\n",
    "            v_instruction_ground_truth = v_next_sentence_label.detach().cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "            if N==0:\n",
    "                v_instruction_predictions_all   = v_instruction_prediction\n",
    "                v_instruction_ground_truths_all = v_instruction_ground_truth\n",
    "\n",
    "                v_masked_token_predictions_all   = v_masked_token_prediction\n",
    "                v_masked_token_ground_truths_all = v_masked_token_ground_truth\n",
    "                \n",
    "                v_seq_predictions_all= v_seq_prediction\n",
    "                v_seq_ground_truths_all = v_seq_ground_truth\n",
    "\n",
    "        \n",
    "\n",
    "            else:\n",
    "                v_instruction_predictions_all   = np.concatenate((v_instruction_predictions_all, v_instruction_prediction))\n",
    "                v_instruction_ground_truths_all = np.concatenate((v_instruction_ground_truths_all, v_instruction_ground_truth))\n",
    "\n",
    "                v_masked_token_predictions_all   = np.concatenate((v_masked_token_predictions_all, v_masked_token_prediction ))\n",
    "                v_masked_token_ground_truths_all = np.concatenate((v_masked_token_ground_truths_all, v_masked_token_ground_truth ))\n",
    "                \n",
    "                v_seq_predictions_all =np.concatenate((v_seq_predictions_all, v_seq_prediction ))\n",
    "                v_seq_ground_truths_all =np.concatenate((v_seq_ground_truths_all, v_seq_ground_truth ))\n",
    "                \n",
    "\n",
    "            \n",
    "\n",
    "        v_instruction_accuracy = (accuracy_score(v_instruction_ground_truths_all,v_instruction_predictions_all))\n",
    "        v_instruction_precision, v_instruction_recall, v_instruction_f1, _ = precision_recall_fscore_support(v_instruction_ground_truths_all,v_instruction_predictions_all, average='binary')\n",
    "\n",
    "\n",
    "        v_masked_token_accuracy = (accuracy_score(v_masked_token_ground_truths_all, v_masked_token_predictions_all))\n",
    "        v_masked_token_precision, v_masked_token_recall, v_masked_token_f1, _ = precision_recall_fscore_support(v_masked_token_ground_truths_all,v_masked_token_predictions_all,average='weighted')\n",
    "\n",
    "\n",
    "        v_seq_accuracy = (accuracy_score(v_seq_predictions_all, v_seq_ground_truths_all))\n",
    "        v_seq_precision, v_seq_recall, v_seq_f1, _ = precision_recall_fscore_support(v_seq_ground_truths_all,v_seq_predictions_all,average='weighted')\n",
    "\n",
    "        print(\"Validation: \", \"Instruction F1: \", v_instruction_f1,  \"   v_masked_token_ F1: \",v_masked_token_f1 ,\" V SEQ F1: \", v_seq_f1)\n",
    "        \n",
    "        v_global_instruction_metrices.append(v_instruction_f1)\n",
    "        v_global_masked_token_metrices.append(v_masked_token_f1) \n",
    "\n",
    "    \n",
    "    plot_graph(global_instruction_metrices, v_global_instruction_metrices, 'Next Sentence Prediction Scores')\n",
    "    plot_graph(global_masked_token_metrices, v_global_masked_token_metrices, 'Masked Token Prediction Scores')\n",
    "    model.save_pretrained(\"./../../models/\"+EXPERIMENT_NAME+\"_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0,1,2,3,4,5]\n",
    "a[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
