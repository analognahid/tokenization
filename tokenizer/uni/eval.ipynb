{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_132744/3274186680.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import sys,os\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from elftools.elf.segments import Segment\n",
    "from capstone import *\n",
    "from capstone.x86 import *\n",
    "\n",
    "import os\n",
    "import json \n",
    "\n",
    "import sys,os\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(1024, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=384, out_features=35000, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=384, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MAX_TOKEN_LEN = 1024\n",
    "BATCH_SIZE = 40\n",
    "epochs = 10\n",
    "\n",
    "EXPERIMENT_NAME = 'cusTokenizer_UNI_35k_ASIS'\n",
    "new_vocab_size = 35000\n",
    "# disassembly_decimal disassembly_all_number_to_words disassembly_decimal \n",
    "data_key = \"disassembly_decimal\"\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction,BertForPreTraining,BertConfig,AutoModelForMaskedLM,get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast ,AutoModelForPreTraining\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"./../../models/\" + EXPERIMENT_NAME)\n",
    "print(tokenizer.pad_token) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# config = BertConfig.from_pretrained(\"./../../models/\"+EXPERIMENT_NAME+\"_model.ckpt\") #\"./../../models/\"+EXPERIMENT_NAME+\"_model.ckpt\"\n",
    "# # Change max_position_embeddings to 1024 in the config\n",
    "# config.max_position_embeddings = 1024\n",
    "# Load the model with the modified config\n",
    "model = BertForPreTraining.from_pretrained(\"./../../models/\"+EXPERIMENT_NAME+\"_model.ckpt\" )\n",
    "# Access and modify the positional embeddings\n",
    "# # The model's `bert` attribute holds the BERT layers\n",
    "# model_bert = model.bert  # This is the BERT model itself (the backbone)\n",
    "# # Resize the position embeddings to accommodate the new max length (1024 tokens)\n",
    "# model_bert.embeddings.position_embeddings = torch.nn.Embedding(1024, model_bert.config.hidden_size)\n",
    "# # Optional: Initialize the new embeddings using the original ones for the first 512 positions\n",
    "# with torch.no_grad():\n",
    "#     model_bert.embeddings.position_embeddings.weight[:512, :] = model_bert.embeddings.position_embeddings.weight[:512, :]\n",
    "\n",
    "\n",
    "# model.resize_token_embeddings(new_vocab_size)\n",
    "\n",
    "\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "Functions Count:  1001 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "DATA_PATH = '/home/raisul/ANALYSED_DATA/tokenization_data_single_functions'\n",
    "\n",
    "TRAIN_DATA_PATH  ='/home/raisul/ANALYSED_DATA/tokenization_data_single_functions/train/'\n",
    "\n",
    "TEST_DATA_PATH   = '/home/raisul/ANALYSED_DATA/tokenization_data_single_functions/test/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_json_files = [os.path.join(TRAIN_DATA_PATH, f) for f in os.listdir(TRAIN_DATA_PATH) ]\n",
    "\n",
    "test_json_files = [os.path.join(TEST_DATA_PATH, f) for f in os.listdir(TEST_DATA_PATH) ]\n",
    "\n",
    "\n",
    "print(len(train_json_files))\n",
    "def read_corpus(json_files):\n",
    "\n",
    "    all = []\n",
    "\n",
    "    for k, j_file in enumerate(json_files):\n",
    "        if k>1000:\n",
    "            break\n",
    "        try:\n",
    "\n",
    "            with open(j_file, 'r') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                funct = data[data_key]['input']\n",
    "                \n",
    "                all.append(funct)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    return all\n",
    "    \n",
    "\n",
    "\n",
    "train_text = read_corpus(train_json_files)\n",
    "test_text  = read_corpus(test_json_files)\n",
    "\n",
    "\n",
    "        \n",
    "# text = text[0:5000]\n",
    "print(\"Functions Count: \",len(train_text), '\\n')\n",
    "example = train_text[10]\n",
    "text = train_text + test_text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDBR64\n",
      "XOR R8D,R8D\n",
      "MOV ESI,104\n",
      "XOR ECX,ECX\n",
      "MOV EDX,104\n",
      "LEA RDI,[8200]\n",
      "LEA RAX,[8212]\n",
      "JMP 5239\n",
      "MOVZX EDX,byte ptr [RAX + 1]\n",
      "ADD RAX,1\n",
      "ADD ECX,1\n",
      "TEST DL,DL\n",
      "JZ 5280\n",
      "CMP SIL,DL\n",
      "JNZ 5224\n",
      "MOVZX ESI,byte ptr [RDI + 1]\n",
      "MOVSXD RCX,ECX\n",
      "ADD RDI,1\n",
      "ADD R8D,1\n",
      "SUB RAX,RCX\n",
      "TEST SIL,SIL\n",
      "JZ 5280\n",
      "MOVZX EDX,byte ptr [RAX]\n",
      "TEST DL,DL\n",
      "JZ 5280\n",
      "XOR ECX,ECX\n",
      "JMP 5239\n",
      "XOR EAX,EAX\n",
      "CMP R8D,5\n",
      "SETZ AL\n",
      "RET\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text[51].split(delim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll assign a 50% probability of using the genuine next sentence, and 50% probability of using another random sentence.\n",
    "\n",
    "To make this simpler, we'll create a *'bag'* of individual sentences to pull from when selecting a random sentence B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105986 2002\n"
     ]
    }
   ],
   "source": [
    "delim = '\\n'\n",
    "bag = [instruction for instruction_cluster in text for instruction in instruction_cluster.split(delim)  if instruction!= '']\n",
    "bag_size = len(bag)\n",
    "print(bag_size , len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we create our 50/50 NIP training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n",
      "['ENDBR64', 'PUSH R12', 'LEA RSI,[4608]', 'MOV EDI,2', 'LEA R12,[8253]', 'PUSH RBP', 'LEA RBP,[8262]', 'PUSH RBX', 'XOR EBX,EBX', 'CALL 4224', 'JMP 4323', 'MOV RDI,RBP', 'ADD EBX,1', 'CALL 4208', 'CMP EBX,10000', 'JZ 4352', 'CMP EBX,100', 'JNZ 4304', 'MOV RDI,R12', 'MOV EBX,101', 'CALL 4208', 'MOV RDI,RBP', 'CALL 4208', 'JMP 4304', 'POP RBX', 'XOR EAX,EAX', 'POP RBP', 'POP R12', 'RET']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "history = []\n",
    "next_instruction = []\n",
    "label = []\n",
    "\n",
    "\n",
    "instruction_pages = []\n",
    "for instruction_cluster in text:\n",
    "    instructions = [\n",
    "        instruction for instruction in instruction_cluster.split(delim) if instruction != ''\n",
    "    ]\n",
    "\n",
    "    instruction_pages.append(instructions)\n",
    "\n",
    "        \n",
    "print(len(instruction_pages))\n",
    "print(instruction_pages[0])\n",
    "\n",
    "for instruction_page in instruction_pages:\n",
    "        # this is IsNextSentence\n",
    "        history.append(delim.join(instruction_page))\n",
    "        next_instruction.append(instruction_page[-1])\n",
    "        label.append(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now ready for tokenization, this time we truncate/pad each token to the same length of *512* tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(history, next_instruction, return_tensors='pt', \n",
    "                   max_length=MAX_TOKEN_LEN, truncation=True, padding=True)\n",
    "ground_truth = inputs.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the *token_type_ids* tensors have been built correctly (eg **1** indicating sentence B tokens) by checking the first instance of *token_type_ids*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the labels tensor is simply a clone of the input_ids tensor before masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T\n",
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we mask tokens in the input_ids tensor using the 15% probability for MLM - ensuring we don't mask CLS, SEP, or PAD tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2002, 986])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr.shape\n",
    "# inputs.input_ids.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now take the indices of each True value within each vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2002,\n",
       " 2002,\n",
       " [[7,\n",
       "   14,\n",
       "   16,\n",
       "   25,\n",
       "   28,\n",
       "   35,\n",
       "   39,\n",
       "   52,\n",
       "   55,\n",
       "   57,\n",
       "   64,\n",
       "   67,\n",
       "   74,\n",
       "   75,\n",
       "   81,\n",
       "   82,\n",
       "   90,\n",
       "   93,\n",
       "   97,\n",
       "   101,\n",
       "   113,\n",
       "   116,\n",
       "   120,\n",
       "   127,\n",
       "   133,\n",
       "   134,\n",
       "   137,\n",
       "   153,\n",
       "   157,\n",
       "   168,\n",
       "   172,\n",
       "   174,\n",
       "   178,\n",
       "   182,\n",
       "   183,\n",
       "   185,\n",
       "   191,\n",
       "   195,\n",
       "   197,\n",
       "   209,\n",
       "   235,\n",
       "   240,\n",
       "   269,\n",
       "   279,\n",
       "   283,\n",
       "   293,\n",
       "   297,\n",
       "   298,\n",
       "   313,\n",
       "   322,\n",
       "   333,\n",
       "   337,\n",
       "   342,\n",
       "   343,\n",
       "   356,\n",
       "   365,\n",
       "   371,\n",
       "   383,\n",
       "   400,\n",
       "   403,\n",
       "   404,\n",
       "   406,\n",
       "   408,\n",
       "   417,\n",
       "   435,\n",
       "   441,\n",
       "   443,\n",
       "   449,\n",
       "   462,\n",
       "   471,\n",
       "   483,\n",
       "   489,\n",
       "   491,\n",
       "   492,\n",
       "   495,\n",
       "   498,\n",
       "   500,\n",
       "   503,\n",
       "   506,\n",
       "   524,\n",
       "   526,\n",
       "   527,\n",
       "   543,\n",
       "   586,\n",
       "   591,\n",
       "   602,\n",
       "   606,\n",
       "   608,\n",
       "   611,\n",
       "   612,\n",
       "   619,\n",
       "   626,\n",
       "   640,\n",
       "   641,\n",
       "   642,\n",
       "   658,\n",
       "   665,\n",
       "   671,\n",
       "   687,\n",
       "   701,\n",
       "   703,\n",
       "   708,\n",
       "   709,\n",
       "   712,\n",
       "   713,\n",
       "   714,\n",
       "   716,\n",
       "   736,\n",
       "   739,\n",
       "   742,\n",
       "   755,\n",
       "   758,\n",
       "   759,\n",
       "   760,\n",
       "   761,\n",
       "   764,\n",
       "   765,\n",
       "   766,\n",
       "   771,\n",
       "   776,\n",
       "   784,\n",
       "   800,\n",
       "   802,\n",
       "   803,\n",
       "   805,\n",
       "   808,\n",
       "   810,\n",
       "   812,\n",
       "   820,\n",
       "   835,\n",
       "   842,\n",
       "   849,\n",
       "   851,\n",
       "   855,\n",
       "   857,\n",
       "   870,\n",
       "   871,\n",
       "   877,\n",
       "   882,\n",
       "   891,\n",
       "   896,\n",
       "   898,\n",
       "   899,\n",
       "   905,\n",
       "   908,\n",
       "   909,\n",
       "   911,\n",
       "   913,\n",
       "   944,\n",
       "   947,\n",
       "   960,\n",
       "   974,\n",
       "   981],\n",
       "  [1,\n",
       "   6,\n",
       "   11,\n",
       "   19,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   39,\n",
       "   41,\n",
       "   46,\n",
       "   62,\n",
       "   67,\n",
       "   73,\n",
       "   82,\n",
       "   91,\n",
       "   97,\n",
       "   101,\n",
       "   106,\n",
       "   108,\n",
       "   120,\n",
       "   124,\n",
       "   125,\n",
       "   126,\n",
       "   128,\n",
       "   155,\n",
       "   157,\n",
       "   163,\n",
       "   178,\n",
       "   189,\n",
       "   200,\n",
       "   216,\n",
       "   219,\n",
       "   227,\n",
       "   231,\n",
       "   234,\n",
       "   241,\n",
       "   244,\n",
       "   249,\n",
       "   258,\n",
       "   260,\n",
       "   269,\n",
       "   300,\n",
       "   317,\n",
       "   340,\n",
       "   346,\n",
       "   350,\n",
       "   351,\n",
       "   359,\n",
       "   364,\n",
       "   379,\n",
       "   380,\n",
       "   389,\n",
       "   391,\n",
       "   400,\n",
       "   412,\n",
       "   413,\n",
       "   417,\n",
       "   418,\n",
       "   422,\n",
       "   438,\n",
       "   446,\n",
       "   452,\n",
       "   458,\n",
       "   462,\n",
       "   463,\n",
       "   472,\n",
       "   473,\n",
       "   492,\n",
       "   497,\n",
       "   501,\n",
       "   502,\n",
       "   508,\n",
       "   510,\n",
       "   511,\n",
       "   513,\n",
       "   524,\n",
       "   538,\n",
       "   546,\n",
       "   547,\n",
       "   549,\n",
       "   558,\n",
       "   581,\n",
       "   585,\n",
       "   597,\n",
       "   612,\n",
       "   615,\n",
       "   616,\n",
       "   630,\n",
       "   637,\n",
       "   642,\n",
       "   648,\n",
       "   662,\n",
       "   670,\n",
       "   679,\n",
       "   680,\n",
       "   688,\n",
       "   708,\n",
       "   713,\n",
       "   720,\n",
       "   735,\n",
       "   742,\n",
       "   744,\n",
       "   748,\n",
       "   752,\n",
       "   777,\n",
       "   778,\n",
       "   782,\n",
       "   783,\n",
       "   784,\n",
       "   786,\n",
       "   789,\n",
       "   791,\n",
       "   796,\n",
       "   811,\n",
       "   813,\n",
       "   817,\n",
       "   822,\n",
       "   826,\n",
       "   831,\n",
       "   844,\n",
       "   849,\n",
       "   852,\n",
       "   858,\n",
       "   860,\n",
       "   873,\n",
       "   874,\n",
       "   878,\n",
       "   882,\n",
       "   894,\n",
       "   904,\n",
       "   910,\n",
       "   914,\n",
       "   915,\n",
       "   918,\n",
       "   921,\n",
       "   925,\n",
       "   932,\n",
       "   933,\n",
       "   944,\n",
       "   957,\n",
       "   972,\n",
       "   979],\n",
       "  [1,\n",
       "   12,\n",
       "   31,\n",
       "   35,\n",
       "   49,\n",
       "   50,\n",
       "   53,\n",
       "   62,\n",
       "   71,\n",
       "   76,\n",
       "   77,\n",
       "   81,\n",
       "   90,\n",
       "   95,\n",
       "   98,\n",
       "   105,\n",
       "   118,\n",
       "   128,\n",
       "   135,\n",
       "   143,\n",
       "   146,\n",
       "   154,\n",
       "   156,\n",
       "   160,\n",
       "   166,\n",
       "   168,\n",
       "   177,\n",
       "   180,\n",
       "   191,\n",
       "   192,\n",
       "   197,\n",
       "   211,\n",
       "   214,\n",
       "   240,\n",
       "   252,\n",
       "   268,\n",
       "   269,\n",
       "   281,\n",
       "   289,\n",
       "   296,\n",
       "   303,\n",
       "   304,\n",
       "   307,\n",
       "   313,\n",
       "   316,\n",
       "   320,\n",
       "   330,\n",
       "   335,\n",
       "   344,\n",
       "   349,\n",
       "   352,\n",
       "   355,\n",
       "   361,\n",
       "   388,\n",
       "   391,\n",
       "   395,\n",
       "   401,\n",
       "   404,\n",
       "   409,\n",
       "   412,\n",
       "   432,\n",
       "   457,\n",
       "   465,\n",
       "   473,\n",
       "   479,\n",
       "   483,\n",
       "   490,\n",
       "   502,\n",
       "   508,\n",
       "   515,\n",
       "   518,\n",
       "   521,\n",
       "   524,\n",
       "   544,\n",
       "   552,\n",
       "   559,\n",
       "   584,\n",
       "   593,\n",
       "   595,\n",
       "   597,\n",
       "   603,\n",
       "   604,\n",
       "   616,\n",
       "   617,\n",
       "   625,\n",
       "   631,\n",
       "   633,\n",
       "   635,\n",
       "   643,\n",
       "   659,\n",
       "   669,\n",
       "   676,\n",
       "   688,\n",
       "   689,\n",
       "   691,\n",
       "   701,\n",
       "   714,\n",
       "   715,\n",
       "   746,\n",
       "   755,\n",
       "   760,\n",
       "   768,\n",
       "   779,\n",
       "   780,\n",
       "   782,\n",
       "   791,\n",
       "   797,\n",
       "   798,\n",
       "   801,\n",
       "   807,\n",
       "   820,\n",
       "   823,\n",
       "   829,\n",
       "   840,\n",
       "   845,\n",
       "   848,\n",
       "   866,\n",
       "   876,\n",
       "   877,\n",
       "   878,\n",
       "   881,\n",
       "   896,\n",
       "   899,\n",
       "   906,\n",
       "   907,\n",
       "   913,\n",
       "   924,\n",
       "   936,\n",
       "   955,\n",
       "   959,\n",
       "   962,\n",
       "   976,\n",
       "   977]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (selection) , len(inputs.input_ids), selection[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then apply these indices to each row in input_ids, assigning each value at these indices a value of 103."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_labels = []\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    masked_labels.append(inputs.input_ids[i, selection[i]])\n",
    "    inputs.input_ids[i, selection[i]] = 103\n",
    "# masked_labels[0]\n",
    "inputs[\"mask_arr\"] = mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels', 'mask_arr'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `inputs` tensors are now ready, and we can begin building the model input pipeline for training. We first create a PyTorch dataset from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeditationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize our data using the `MeditationDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MeditationsDataset(inputs)\n",
    "# print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 1001)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_dataset  = torch.utils.data.Subset(dataset, range(len(train_text)))\n",
    "validation_dataset = torch.utils.data.Subset(dataset, range(len(train_text) , len(dataset)))\n",
    "\n",
    "len(train_dataset) , len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And initialize the dataloader, which we'll be using to load our data into the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the training mode of our model, and initialize our optimizer (Adam with weighted decay - reduces chance of overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto the training loop, we'll train for a couple of epochs (change `epochs` to modify this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odict_keys(['loss', 'prediction_logits', 'seq_relationship_logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graph(training_data, validation_data , label ):\n",
    "\n",
    "    font_size = 10\n",
    "    x_labels = [ i for i in range(len(training_data)) ]\n",
    "\n",
    "    plt.ylabel(' F1 ',fontsize=font_size)\n",
    "    plt.plot(x_labels, training_data , 'r') \n",
    "    plt.plot(x_labels, validation_data , 'b') \n",
    "    plt.xlabel(\"Epoch\", fontsize=font_size)\n",
    "    plt.title(label,fontsize=font_size)\n",
    "    plt.legend(['Training', 'Validation'], loc='upper left') \n",
    "    \n",
    "    plt.savefig('./../../results/'+EXPERIMENT_NAME+label+'.pdf')\n",
    "    plt.show()\n",
    "    with open('./../../results/'+EXPERIMENT_NAME+label+'.json', 'w') as json_file:\n",
    "        json.dump([training_data, validation_data , label], json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=3e-4 ,weight_decay=0.0001)\n",
    "\n",
    "# Number of training steps per epoch\n",
    "train_steps = len(train_loader)\n",
    "\n",
    "# Define the number of total training steps and warmup steps\n",
    "total_steps = train_steps * epochs\n",
    "warmup_steps = int(total_steps * 0.1)  # 10% of total steps as warmup\n",
    "\n",
    "# Scheduler setup\n",
    "scheduler = get_linear_schedule_with_warmup(optim,\n",
    "                                            num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                            | 0/26 [00:00<?, ?it/s]/tmp/ipykernel_132744/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "  0%|                                            | 0/26 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████| 26/26 [00:05<00:00,  4.43it/s]\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation:  Instruction F1:  0.0    v_masked_token_ F1:  0.8168453503044859 v_seq_accuracy:  0.9924011080197693  v_masked_token_precision :  0.8143182597939271 v_masked_token_recall: 0.8272808075677734  V SEQ F1:  0.9920799235527512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                            | 0/26 [00:00<?, ?it/s]/tmp/ipykernel_132744/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "  0%|                                            | 0/26 [00:00<?, ?it/s]\n",
      " 62%|█████████████████████▌             | 16/26 [00:04<00:02,  3.99it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 165\u001b[0m\n\u001b[1;32m    162\u001b[0m v_masked_token_prediction \u001b[38;5;241m=\u001b[39m [ token[v_batch_masks[t]]\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m t,token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(v_token_prediction) ]\n\u001b[1;32m    163\u001b[0m v_masked_token_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chain\u001b[38;5;241m.\u001b[39mfrom_iterable(v_masked_token_prediction))\n\u001b[0;32m--> 165\u001b[0m v_masked_token_ground_truth   \u001b[38;5;241m=\u001b[39m [ \u001b[43mtoken\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv_batch_masks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t,token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(v_labels) ]\n\u001b[1;32m    166\u001b[0m v_masked_token_ground_truth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chain\u001b[38;5;241m.\u001b[39mfrom_iterable(v_masked_token_ground_truth))\n\u001b[1;32m    168\u001b[0m filteredP \u001b[38;5;241m=\u001b[39m[]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "counter = 0\n",
    "\n",
    "global_instruction_metrices = []\n",
    "global_masked_token_metrices = []\n",
    "\n",
    "v_global_instruction_metrices = []\n",
    "v_global_masked_token_metrices = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    train_loop = tqdm(train_loader, leave=True)\n",
    "    \n",
    "    \n",
    "    instruction_predictions_all, instruction_ground_truths_all = None, None\n",
    "    masked_token_predictions_all, masked_token_ground_truths_all = None, None\n",
    "    seq_predictions_all, seq_ground_truths_all = None, None\n",
    "    \n",
    "    # activate training mode\n",
    "    model.train()\n",
    "    for N,batch in enumerate(train_loop):\n",
    "        break\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        next_sentence_label = batch['next_sentence_label'].to(device)\n",
    "        batch_mask_arr = batch ['mask_arr']\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        next_sentence_label=next_sentence_label,\n",
    "                        labels=labels)\n",
    "\n",
    "\n",
    "        token_prediction = torch.argmax(outputs.prediction_logits, axis=-1)\n",
    "       \n",
    "\n",
    "\n",
    "        # batch_masks = selection [BATCH_SIZE*N : (BATCH_SIZE*(N+1))]\n",
    "        # print('batch_masks old: ',batch_masks)\n",
    "\n",
    "        # print(batch ['mask_arr'].shape) #torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        batch_masks =   [ torch.flatten(bm.nonzero()).tolist()  for bm in batch_mask_arr]    # torch.flatten(batch ['mask_arr'].nonzero()).tolist()\n",
    "        # print('batch_masks new: ',batch_masks)\n",
    "        \n",
    "        # print(\"BATCH_SIZE*N : (BATCH_SIZE*(N+1)): \",BATCH_SIZE*N , (BATCH_SIZE*(N+1)) )\n",
    "        # print(\"batch_masks:\",batch_masks)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        masked_token_prediction = [ token[batch_masks[t]].tolist() for t,token in enumerate(token_prediction) ]\n",
    "        masked_token_prediction = list(chain.from_iterable(masked_token_prediction))\n",
    "        \n",
    "        masked_token_ground_truth   = [ token[batch_masks[t]].tolist() for t,token in enumerate(labels) ]\n",
    "        masked_token_ground_truth = list(chain.from_iterable(masked_token_ground_truth))\n",
    "        \n",
    "\n",
    "        # print(token_prediction , token_ground_truth)\n",
    "\n",
    "        # token_prediction = token_prediction.detach().cpu().numpy().flatten()\n",
    "        # token_ground_truth = labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "        # print(\"token_prediction  : \", token_prediction)\n",
    "        # print(\"token_ground_truth: \", token_ground_truth)\n",
    "\n",
    "\n",
    "        seq_predictions   = token_prediction.detach().cpu().numpy().flatten()\n",
    "        seq_ground_truths = labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "        \n",
    "        instruction_prediction = torch.argmax(outputs.seq_relationship_logits, axis=-1)\n",
    "        instruction_prediction   = instruction_prediction.detach().cpu().numpy().flatten()\n",
    "        instruction_ground_truth = next_sentence_label.detach().cpu().numpy().flatten()\n",
    "        \n",
    "        if N==0:\n",
    "            instruction_predictions_all   = instruction_prediction\n",
    "            instruction_ground_truths_all = instruction_ground_truth\n",
    "            \n",
    "            masked_token_predictions_all         = masked_token_prediction\n",
    "            masked_token_ground_truths_all       = masked_token_ground_truth  \n",
    "\n",
    "\n",
    "            seq_predictions_all = seq_predictions\n",
    "            seq_ground_truths_all = seq_ground_truths\n",
    "            \n",
    "        else:\n",
    "            instruction_predictions_all   = np.concatenate((instruction_predictions_all, instruction_prediction))\n",
    "            instruction_ground_truths_all = np.concatenate((instruction_ground_truths_all, instruction_ground_truth))\n",
    "            \n",
    "            masked_token_predictions_all   = np.concatenate((masked_token_predictions_all, masked_token_prediction))\n",
    "            masked_token_ground_truths_all = np.concatenate((masked_token_ground_truths_all, masked_token_ground_truth))\n",
    "\n",
    "            seq_predictions_all = np.concatenate((seq_predictions_all, seq_predictions))\n",
    "            seq_ground_truths_all = np.concatenate((seq_ground_truths_all, seq_ground_truths))\n",
    "            \n",
    "\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "        # print relevant info to progress bar\n",
    "        train_loop.set_description(f'Epoch {epoch}')\n",
    "        train_loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    \n",
    "    # instruction_accuracy = (accuracy_score(instruction_ground_truths_all,instruction_predictions_all))\n",
    "    # instruction_precision, instruction_recall, instruction_f1, _ = precision_recall_fscore_support(instruction_ground_truths_all,instruction_predictions_all, average='binary')\n",
    "    \n",
    "    # masked_token_accuracy = (accuracy_score(masked_token_ground_truths_all, masked_token_predictions_all))\n",
    "    # masked_token_precision, masked_token_recall, masked_token_f1, _ = precision_recall_fscore_support(masked_token_ground_truths_all,masked_token_predictions_all,average='weighted')\n",
    "\n",
    "    # seq_precision, seq_recall, seq_f1, _ = precision_recall_fscore_support(seq_ground_truths_all,seq_predictions_all,average='weighted')\n",
    "    \n",
    "    # print(\"Training: \",  ' Instruction f1: ', instruction_f1 , '  Masked Token f1: ',masked_token_f1 , ' masked_token_precision: ', masked_token_precision, ' masked_token_recall: ', masked_token_recall, ' masked_token_accuracy ', masked_token_accuracy,\"    SEQ F1\",seq_f1)\n",
    "    # global_instruction_metrices.append(instruction_f1)\n",
    "    # global_masked_token_metrices.append( masked_token_f1) \n",
    "\n",
    "    ###########################################\n",
    "    ###############  EVAL Validation  #########\n",
    "    ###########################################\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "#         v_predictions_all, v_ground_truths_all = None, None\n",
    "        \n",
    "        v_instruction_predictions_all, v_instruction_ground_truths_all = None, None\n",
    "        v_masked_token_predictions_all, v_masked_token_ground_truths_all = None, None\n",
    "        v_seq_predictions_all, v_seq_ground_truths_all = None, None\n",
    "    \n",
    "    \n",
    "        validation_loop = tqdm(validation_loader, leave=True)\n",
    "        for N,v_batch in enumerate(validation_loop):\n",
    "            \n",
    "            \n",
    "            \n",
    "            v_input_ids = v_batch['input_ids'].to(device)\n",
    "            v_token_type_ids = v_batch['token_type_ids'].to(device)\n",
    "            v_attention_mask = v_batch['attention_mask'].to(device)\n",
    "            v_next_sentence_label = v_batch['next_sentence_label'].to(device)\n",
    "            v_mask_arr = v_batch ['mask_arr']\n",
    "            v_labels = v_batch['labels'].to(device)\n",
    "            # process\n",
    "            v_outputs = model(v_input_ids, attention_mask=v_attention_mask,\n",
    "                            token_type_ids=v_token_type_ids,\n",
    "                            next_sentence_label=v_next_sentence_label,\n",
    "                            labels=v_labels)\n",
    "        \n",
    "            v_token_prediction = torch.argmax(v_outputs.prediction_logits, axis=-1)\n",
    "\n",
    "                    \n",
    "\n",
    "            v_batch_masks =   [ torch.flatten(bm.nonzero()).tolist()  for bm in v_mask_arr]\n",
    "            \n",
    "            v_masked_token_prediction = [ token[v_batch_masks[t]].tolist() for t,token in enumerate(v_token_prediction) ]\n",
    "            v_masked_token_prediction = list(chain.from_iterable(v_masked_token_prediction))\n",
    "            \n",
    "            v_masked_token_ground_truth   = [ token[v_batch_masks[t]].tolist() for t,token in enumerate(v_labels) ]\n",
    "            v_masked_token_ground_truth = list(chain.from_iterable(v_masked_token_ground_truth))\n",
    "\n",
    "            filteredP =[]\n",
    "            filteredG = []\n",
    "            for gi,g in enumerate(v_masked_token_ground_truth):\n",
    "                if g!=2 and g!=103:\n",
    "                    filteredG.append(v_masked_token_ground_truth [gi])\n",
    "                    filteredP.append(v_masked_token_prediction[gi])\n",
    "\n",
    "            v_masked_token_ground_truth = filteredG\n",
    "            v_masked_token_prediction = filteredP\n",
    "\n",
    "            v_seq_prediction = v_token_prediction.detach().cpu().numpy().flatten()\n",
    "            v_seq_ground_truth = v_labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            # token_prediction = [ token[batch_masks[t]].tolist() for t,token in enumerate(token_prediction) ]\n",
    "            # token_prediction = list(chain.from_iterable(token_prediction))\n",
    "            \n",
    "            # token_ground_truth   = [ token[batch_masks[t]].tolist() for t,token in enumerate(labels) ]\n",
    "            # token_ground_truth = list(chain.from_iterable(token_ground_truth))\n",
    "\n",
    "            \n",
    "            v_instruction_prediction = torch.argmax(v_outputs.seq_relationship_logits, axis=-1)\n",
    "            v_instruction_prediction   = v_instruction_prediction.detach().cpu().numpy().flatten()\n",
    "            v_instruction_ground_truth = v_next_sentence_label.detach().cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "            if N==0:\n",
    "                v_instruction_predictions_all   = v_instruction_prediction\n",
    "                v_instruction_ground_truths_all = v_instruction_ground_truth\n",
    "\n",
    "                v_masked_token_predictions_all   = v_masked_token_prediction\n",
    "                v_masked_token_ground_truths_all = v_masked_token_ground_truth\n",
    "                \n",
    "                v_seq_predictions_all= v_seq_prediction\n",
    "                v_seq_ground_truths_all = v_seq_ground_truth\n",
    "\n",
    "        \n",
    "\n",
    "            else:\n",
    "                v_instruction_predictions_all   = np.concatenate((v_instruction_predictions_all, v_instruction_prediction))\n",
    "                v_instruction_ground_truths_all = np.concatenate((v_instruction_ground_truths_all, v_instruction_ground_truth))\n",
    "\n",
    "                v_masked_token_predictions_all   = np.concatenate((v_masked_token_predictions_all, v_masked_token_prediction ))\n",
    "                v_masked_token_ground_truths_all = np.concatenate((v_masked_token_ground_truths_all, v_masked_token_ground_truth ))\n",
    "                \n",
    "                v_seq_predictions_all =np.concatenate((v_seq_predictions_all, v_seq_prediction ))\n",
    "                v_seq_ground_truths_all =np.concatenate((v_seq_ground_truths_all, v_seq_ground_truth ))\n",
    "                \n",
    "\n",
    "            \n",
    "\n",
    "        v_instruction_accuracy = (accuracy_score(v_instruction_ground_truths_all,v_instruction_predictions_all))\n",
    "        v_instruction_precision, v_instruction_recall, v_instruction_f1, _ = precision_recall_fscore_support(v_instruction_ground_truths_all,v_instruction_predictions_all, average='binary')\n",
    "\n",
    "\n",
    "        v_masked_token_accuracy = (accuracy_score(v_masked_token_ground_truths_all, v_masked_token_predictions_all))\n",
    "        v_masked_token_precision, v_masked_token_recall, v_masked_token_f1, _ = precision_recall_fscore_support(v_masked_token_ground_truths_all,v_masked_token_predictions_all,average='weighted')\n",
    "\n",
    "\n",
    "        v_seq_accuracy = (accuracy_score(v_seq_predictions_all, v_seq_ground_truths_all))\n",
    "        v_seq_precision, v_seq_recall, v_seq_f1, _ = precision_recall_fscore_support(v_seq_ground_truths_all,v_seq_predictions_all,average='weighted')\n",
    "    \n",
    "        print(epoch,\"Validation: \", \"Instruction F1: \", v_instruction_f1,  \"   v_masked_token_ F1: \",v_masked_token_f1,'v_seq_accuracy: ',v_seq_accuracy,' v_masked_token_precision : ',v_masked_token_precision,'v_masked_token_recall:', v_masked_token_recall,\" V SEQ F1: \", v_seq_f1)\n",
    "        \n",
    "        v_global_instruction_metrices.append(v_instruction_f1)\n",
    "        v_global_masked_token_metrices.append(v_masked_token_f1) \n",
    "\n",
    "    \n",
    "    # plot_graph(global_instruction_metrices, v_global_instruction_metrices, 'Next Sentence Prediction Scores')\n",
    "    # plot_graph(global_masked_token_metrices, v_global_masked_token_metrices, 'Masked Token Prediction Scores')\n",
    "    # model.save_pretrained(\"./../../models/\"+EXPERIMENT_NAME+\"_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0,1,2,3,4,5]\n",
    "a[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
