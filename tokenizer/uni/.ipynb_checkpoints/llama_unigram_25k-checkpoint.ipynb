{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "#!/usr/bin/env python3\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import sys,os\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from elftools.elf.segments import Segment\n",
    "from capstone import *\n",
    "from capstone.x86 import *\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, Trainer, TrainingArguments,LlamaModel,LlamaForSequenceClassification,LlamaTokenizerFast\n",
    "import os\n",
    "import json \n",
    "import torch, os,re\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "from num2words import num2words\n",
    "\n",
    "from trl import SFTTrainer\n",
    "# import torch\n",
    "\n",
    "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "# from torch.distributed.fsdp.wrap import auto_wrap\n",
    "\n",
    "\n",
    "login(token = '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')\n",
    "\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import sys,os\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n",
      "The class this function is called from is 'LlamaTokenizerFast'.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): CompressedLinear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): CompressedLinear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): CompressedLinear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): CompressedLinear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): CompressedLinear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): CompressedLinear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): CompressedLinear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MAX_TOKEN_LEN = 1024\n",
    "BATCH_SIZE =30\n",
    "EXPERIMENT_NAME = 'cusTokenizer_UNI_25k_ASIS'\n",
    "\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction,BertForPreTraining\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer = LlamaTokenizerFast.from_pretrained(\"./../../models/\" + EXPERIMENT_NAME)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# Load the model\n",
    "model = LlamaForCausalLM.from_pretrained('neuralmagic/Llama-3.2-1B-Instruct-quantized.w8a8')  # 'meta-llama/Llama-3.2-1B'\n",
    " \n",
    "\n",
    "# model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "Functions Count:  10001 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_key = \"disassembly_decimal\"\n",
    "DATA_PATH = '/home/raisul/ANALYSED_DATA/tokenization_data_single_functions'\n",
    "\n",
    "TRAIN_DATA_PATH  ='/home/raisul/ANALYSED_DATA/tokenization_data_single_functions/train/'\n",
    "\n",
    "TEST_DATA_PATH   = '/home/raisul/ANALYSED_DATA/tokenization_data_single_functions/test/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_json_files = [os.path.join(TRAIN_DATA_PATH, f) for f in os.listdir(TRAIN_DATA_PATH) ]\n",
    "\n",
    "test_json_files = [os.path.join(TEST_DATA_PATH, f) for f in os.listdir(TEST_DATA_PATH) ]\n",
    "\n",
    "\n",
    "print(len(train_json_files))\n",
    "def read_corpus(json_files):\n",
    "\n",
    "    all = []\n",
    "\n",
    "    for k, j_file in enumerate(json_files):\n",
    "        if k>10000:\n",
    "            break\n",
    "        try:\n",
    "\n",
    "            with open(j_file, 'r') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                funct = data[data_key]['input']\n",
    "                \n",
    "                all.append(funct)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    return all\n",
    "    \n",
    "\n",
    "\n",
    "train_text = read_corpus(train_json_files)\n",
    "test_text  = read_corpus(test_json_files)\n",
    "\n",
    "\n",
    "        \n",
    "# text = text[0:5000]\n",
    "print(\"Functions Count: \",len(train_text), '\\n')\n",
    "example = train_text[10]\n",
    "text = train_text + test_text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDBR64\n",
      "PXOR XMM0,XMM0\n",
      "LEA R9,[RDI + 36]\n",
      "LEA RCX,[RSI + 12]\n",
      "SUB RSP,56\n",
      "MOV RAX,qword ptr FS:[40]\n",
      "MOV qword ptr [RSP + 40],RAX\n",
      "XOR EAX,EAX\n",
      "MOV dword ptr [RSP + 32],0\n",
      "MOV R10,RSP\n",
      "MOVAPS xmmword ptr [RSP],XMM0\n",
      "MOV R8,R10\n",
      "MOVAPS xmmword ptr [RSP + 16],XMM0\n",
      "MOVSS XMM4,dword ptr [RDI]\n",
      "MOVSS XMM3,dword ptr [RDI + 4]\n",
      "MOV RAX,RSI\n",
      "MOV RDX,R8\n",
      "MOVSS XMM2,dword ptr [RDI + 8]\n",
      "MOVSS XMM1,dword ptr [RAX + 12]\n",
      "MOVSS XMM0,dword ptr [RAX]\n",
      "ADD RAX,4\n",
      "ADD RDX,4\n",
      "MULSS XMM1,XMM3\n",
      "MULSS XMM0,XMM4\n",
      "ADDSS XMM0,dword ptr [RDX + -4]\n",
      "ADDSS XMM0,XMM1\n",
      "MOVSS XMM1,dword ptr [RAX + 20]\n",
      "MULSS XMM1,XMM2\n",
      "ADDSS XMM0,XMM1\n",
      "MOVSS dword ptr [RDX + -4],XMM0\n",
      "CMP RCX,RAX\n",
      "JNZ 4959\n",
      "ADD RDI,12\n",
      "ADD R8,12\n",
      "CMP RDI,R9\n",
      "JNZ 4939\n",
      "MOV RDI,R10\n",
      "CALL 4656\n",
      "MOV RAX,qword ptr [RSP + 40]\n",
      "SUB RAX,qword ptr FS:[40]\n",
      "JNZ 5058\n",
      "ADD RSP,56\n",
      "RET\n",
      "CALL 4224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 25001 3 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sep_token_id = tokenizer.sep_token_id\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "cls_token_id = tokenizer.cls_token_id\n",
    "mask_token_id= tokenizer.mask_token_id\n",
    "\n",
    "print(sep_token_id,pad_token_id,cls_token_id ,mask_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we create our 50/50 NIP training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now ready for tokenization, this time we truncate/pad each token to the same length of *1024* tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = tokenizer(text,return_tensors='pt',max_length=MAX_TOKEN_LEN, truncation=True, padding=True)\n",
    "ground_truth = inputs.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the *token_type_ids* tensors have been built correctly (eg **1** indicating sentence B tokens) by checking the first instance of *token_type_ids*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
      "        25001, 25001, 25001, 25001, 25000,    38,    22,    92,    17,   910,\n",
      "        20028,    27,    34,    17, 11266,    22,    67,    17, 15821,    22,\n",
      "            6,   157,   789,    14,    15,   164,    26, 13583,  1228,   146,\n",
      "           14,    15,    90,    24,   156,  8322,    19,   190,    24,  6048,\n",
      "          107,    19,   120,   457,  5803,  2741,    14,    15,   133,   122,\n",
      "           14,    15,   448,    26,   143,    60,     6,   157,    56,    21,\n",
      "           39,    21,   188])\n",
      "</s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> <s> ▁ENDBR64\n",
      " PUSH ▁R12\n",
      " LEA ▁RSI,[ 4608]\n",
      " MOV ▁EDI,2\n",
      " LEA ▁R12,[8253]\n",
      " PUSH ▁RBP\n",
      " LEA ▁RBP,[8262]\n",
      " PUSH ▁ RBX\n",
      "XOR ▁EBX,EBX\n",
      "C A LL ▁4224\n",
      "J MP ▁4323\n",
      "MOV ▁RDI,RBP\n",
      "ADD ▁EBX,1\n",
      "C A LL ▁4208\n",
      " CMP ▁EBX, 10000\n",
      "J Z ▁4352\n",
      " CMP ▁EBX,100\n",
      "J N Z ▁4304\n",
      "MOV ▁RDI,R12\n",
      "MOV ▁EBX,10 1\n",
      "C A LL ▁4208\n",
      "MOV ▁RDI,RBP\n",
      "C A LL ▁4208\n",
      "J MP ▁4304\n",
      " POP ▁ RBX\n",
      "XOR ▁EAX,EAX \n",
      "POP ▁RBP \n",
      "POP ▁R12\n",
      "RET\n",
      "\n",
      "\n",
      "-->>>>\n",
      " ENDBR64\n",
      "PUSH R12\n",
      "LEA RSI,[4608]\n",
      "MOV EDI,2\n",
      "LEA R12,[8253]\n",
      "PUSH RBP\n",
      "LEA RBP,[8262]\n",
      "PUSH RBX\n",
      "XOR EBX,EBX\n",
      "CALL 4224\n",
      "JMP 4323\n",
      "MOV RDI,RBP\n",
      "ADD EBX,1\n",
      "CALL 4208\n",
      "CMP EBX,10000\n",
      "JZ 4352\n",
      "CMP EBX,100\n",
      "JNZ 4304\n",
      "MOV RDI,R12\n",
      "MOV EBX,101\n",
      "CALL 4208\n",
      "MOV RDI,RBP\n",
      "CALL 4208\n",
      "JMP 4304\n",
      "POP RBX\n",
      "XOR EAX,EAX\n",
      "POP RBP\n",
      "POP R12\n",
      "RET\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inputs.input_ids[0])\n",
    "print(tokenizer.decode(inputs.input_ids[0]))\n",
    "print('\\n-->>>>\\n',text[0])\n",
    "# inputs.token_type_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **0** tokens following our sentence B tokens correspond to *PAD* tokens.\n",
    "\n",
    "Alongside this, we need to create a *labels* tensor too - which corresponds to the values contained within our `label` variable. Our *labels* tensor must be a *LongTensor*, and we will need to transpose the tensor so that it matches our other tensors' dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs['labels'] = inputs.input_ids.copy()\n",
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25000,    38,   132,    18,   495,    17,  1734,     6,    13,\n",
       "         1063,    17,  2127,     6,    13,  2492,   494,    23,    16,    12,\n",
       "           11,     7,     8,     6,    10,     9,     7,    32,    27,     6,\n",
       "           16,    12,    11,     7,     8,     6,    10,     9,     7,    20,\n",
       "            6,    13,   243,    18,    53,     6,     8,    12,    11,     7,\n",
       "            8,     6,    10,     9,     7,    20,     6,    13,  1669, 15373,\n",
       "           14,   137,     6,    55,    33,    33,    12,    11,     7,     8,\n",
       "            6,    10,     9,     7,   607, 10183,   445,    52,     6,    55,\n",
       "           33,    33,    12,    11,     7,     8,     6,    10,     9,     7,\n",
       "           20,     6,    13,  1017,   113,   611,     8,    12,    11,     7,\n",
       "            8,     6,    10,     9,     7,   341,   113,   405,     8,    12,\n",
       "           11,     7,     8,     6,    10,     9,     7,    91,     6,    13,\n",
       "          102,  2231,  3888,   113,   233,     8,    12,    11,     7,     8,\n",
       "            6,    10,     9,     7,    91,     6,    13,    97,   113,   134,\n",
       "            8,    12,    11,     7,     8,     6,    10,     9,     7,    44,\n",
       "            6,    13,   161,   113,    66,     8,    12,    11,     7,     8,\n",
       "            6,    10,     9,     7,   392,  1044,  2155,    79,   113, 11814,\n",
       "           52, 16625,    52,    66,     8,    12,    11,     7,     8,     6,\n",
       "           10,     9,     7,   111,     6,    13,  1784,   113,   679,   113,\n",
       "          134,     8,    12,    11,     7,     8,     6,    10,     9,     7,\n",
       "           44,     6,    13,  3177,    52,  5482,    52,   679,   113,     6,\n",
       "            8,    12,    11,     7,     8,     6,    10,     9,     7,   111,\n",
       "            6,    13,  5760,    24,  1365,    19,  6106,    31,    62,  5539,\n",
       "          274,  3241,    26,  7163,    19, 11862,  8406,    14,    15,   564,\n",
       "           23,    16,    12,    11,     7,     8,     6,    10,     9,     7,\n",
       "           20,     6,    13,   255,    23,    16,    12,    11,     7,     8,\n",
       "            6,    10,     9,     7,    32,    42,    19,  7982,    31,  2476,\n",
       "           14,    15,    68])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[-1]\n",
    "# tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we mask tokens in the input_ids tensor using the 15% probability for MLM - ensuring we don't mask CLS, SEP, or PAD tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now take the indices of each True value within each vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20002,\n",
       " 20002,\n",
       " [[934, 935, 949, 961, 971, 976],\n",
       "  [529,\n",
       "   541,\n",
       "   542,\n",
       "   544,\n",
       "   547,\n",
       "   569,\n",
       "   581,\n",
       "   582,\n",
       "   588,\n",
       "   597,\n",
       "   601,\n",
       "   604,\n",
       "   610,\n",
       "   613,\n",
       "   620,\n",
       "   624,\n",
       "   630,\n",
       "   638,\n",
       "   639,\n",
       "   641,\n",
       "   643,\n",
       "   644,\n",
       "   646,\n",
       "   649,\n",
       "   654,\n",
       "   660,\n",
       "   662,\n",
       "   669,\n",
       "   680,\n",
       "   701,\n",
       "   708,\n",
       "   710,\n",
       "   713,\n",
       "   723,\n",
       "   727,\n",
       "   734,\n",
       "   744,\n",
       "   758,\n",
       "   785,\n",
       "   793,\n",
       "   796,\n",
       "   797,\n",
       "   799,\n",
       "   816,\n",
       "   821,\n",
       "   825,\n",
       "   828,\n",
       "   836,\n",
       "   846,\n",
       "   853,\n",
       "   871,\n",
       "   872,\n",
       "   876,\n",
       "   880,\n",
       "   893,\n",
       "   911,\n",
       "   913,\n",
       "   914,\n",
       "   945,\n",
       "   946,\n",
       "   958,\n",
       "   962,\n",
       "   972,\n",
       "   973,\n",
       "   974],\n",
       "  [794,\n",
       "   796,\n",
       "   800,\n",
       "   809,\n",
       "   829,\n",
       "   838,\n",
       "   841,\n",
       "   843,\n",
       "   847,\n",
       "   854,\n",
       "   855,\n",
       "   857,\n",
       "   860,\n",
       "   861,\n",
       "   872,\n",
       "   882,\n",
       "   889,\n",
       "   907,\n",
       "   912,\n",
       "   922,\n",
       "   927,\n",
       "   930,\n",
       "   936,\n",
       "   941,\n",
       "   948,\n",
       "   950,\n",
       "   955,\n",
       "   956,\n",
       "   964,\n",
       "   979,\n",
       "   982]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (selection) , len(inputs.input_ids), selection[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then apply these indices to each row in input_ids, assigning each value at these indices a value of 103."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11266,    22,   146,    19,    15,     6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[0][selection[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_labels = []\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    masked_labels.append(inputs.input_ids[i, selection[i]])\n",
    "    inputs.input_ids[i, selection[i]] = mask_token_id\n",
    "\n",
    "inputs[\"mask_arr\"] = mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001, 25001,\n",
       "        25001, 25000,    38,   132,     5,   495,    17,  1734,     6,    13,\n",
       "         1063,    17,  2127,     6,    13,  2492,   494,    23,    16,    12,\n",
       "           11,     7,     8,     6,    10,     9,     7,     5,    27,     5,\n",
       "           16,    12,    11,     7,     8,     6,    10,     9,     7,    20,\n",
       "            6,    13,   243,    18,    53,     6,     8,     5,    11,     7,\n",
       "            8,     6,    10,     9,     7,     5,     6,     5,     5, 15373,\n",
       "           14,     5,     6,    55,    33,    33,    12,     5,     7,     8,\n",
       "            6,     5,     5,     7,   607, 10183,     5,    52,     6,    55,\n",
       "            5,    33,    12,     5,     5,     8,     6,    10,     9,     7,\n",
       "           20,     6,    13,     5,   113,   611,     8,    12,    11,     7,\n",
       "            8,     6,    10,     9,     7,   341,     5,   405,     5,     5,\n",
       "           11,     5,     8,     6,    10,     9,     7,    91,     5,    13,\n",
       "          102,  2231,  3888,   113,   233,     8,    12,    11,     7,     8,\n",
       "            6,    10,     9,     7,    91,     6,     5,     5,   113,   134,\n",
       "            8,    12,    11,     7,     5,     6,    10,     9,     5,    44,\n",
       "            6,     5,   161,   113,    66,     8,    12,    11,     7,     8,\n",
       "            6,    10,     9,     7,   392,     5,  2155,    79,   113, 11814,\n",
       "           52, 16625,    52,    66,     5,    12,     5,     7,     8,     6,\n",
       "           10,     9,     5,   111,     6,    13,  1784,   113,   679,   113,\n",
       "          134,     8,    12,    11,     7,     8,     6,    10,     9,     7,\n",
       "           44,     6,     5,     5,     5,  5482,    52,   679,     5,     6,\n",
       "            8,    12,    11,     7,     5,     6,    10,     5,     7,   111,\n",
       "            6,    13,  5760,     5,  1365,    19,  6106,    31,    62,  5539,\n",
       "          274,     5,    26,  7163,    19, 11862,  8406,    14,     5,   564,\n",
       "           23,    16,    12,    11,     7,     8,     6,    10,     9,     7,\n",
       "            5,     6,    13,   255,    23,     5,     5,    11,     7,     8,\n",
       "            6,     5,     9,     7,     5,     5,    19,  7982,    31,  2476,\n",
       "           14,    15,    68])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `inputs` tensors are now ready, and we can begin building the model input pipeline for training. We first create a PyTorch dataset from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeditationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize our data using the `MeditationDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MeditationsDataset(inputs)\n",
    "# print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20002\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 10001) range(10001, 20002)\n"
     ]
    }
   ],
   "source": [
    "print( range(len(train_text)), range(len(train_text) , len(dataset)  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001, 10001)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_dataset  = torch.utils.data.Subset(dataset, range(len(train_text)))\n",
    "validation_dataset = torch.utils.data.Subset(dataset, range(len(train_text) , len(dataset)))\n",
    "\n",
    "len(train_dataset) , len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And initialize the dataloader, which we'll be using to load our data into the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto setting up the training loop. First we setup GPU/CPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): CompressedLinear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): CompressedLinear(in_features=2048, out_features=512, bias=False)\n",
       "          (v_proj): CompressedLinear(in_features=2048, out_features=512, bias=False)\n",
       "          (o_proj): CompressedLinear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): CompressedLinear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): CompressedLinear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): CompressedLinear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the training mode of our model, and initialize our optimizer (Adam with weighted decay - reduces chance of overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto the training loop, we'll train for a couple of epochs (change `epochs` to modify this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odict_keys(['loss', 'prediction_logits', 'seq_relationship_logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graph(training_data, validation_data , label ):\n",
    "\n",
    "    font_size = 10\n",
    "    x_labels = [ i for i in range(len(training_data)) ]\n",
    "\n",
    "    plt.ylabel(' F1 ',fontsize=font_size)\n",
    "    plt.plot(x_labels, training_data , 'r') \n",
    "    plt.plot(x_labels, validation_data , 'b') \n",
    "    plt.xlabel(\"Epoch\", fontsize=font_size)\n",
    "    plt.title(label,fontsize=font_size)\n",
    "    plt.legend(['Training', 'Validation'], loc='upper left') \n",
    "    \n",
    "    plt.savefig('./../../results/'+EXPERIMENT_NAME+label+'.pdf')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|                                           | 0/334 [00:00<?, ?it/s]/tmp/ipykernel_3201949/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|████████████| 334/334 [09:20<00:00,  1.68s/it, loss=0.621]\n",
      "100%|█████████████████████████████████| 334/334 [07:46<00:00,  1.40s/it]\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: acc  0.24006511109259746    v_masked_token_ F1:  0.203248957953577  V SEQ F1:  0.6091692508172256 v_seq_accuracy 0.6331622816951664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                           | 0/334 [00:00<?, ?it/s]/tmp/ipykernel_3201949/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 1: 100%|█████████████| 334/334 [09:28<00:00,  1.70s/it, loss=0.39]\n",
      "100%|█████████████████████████████████| 334/334 [07:45<00:00,  1.39s/it]\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: acc  0.2513634237155619    v_masked_token_ F1:  0.21863833412766484  V SEQ F1:  0.6723266962059167 v_seq_accuracy 0.6875112106868563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                           | 0/334 [00:00<?, ?it/s]/tmp/ipykernel_3201949/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 2:  23%|███          | 78/334 [02:12<07:17,  1.71s/it, loss=0.638]"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "from itertools import chain\n",
    "\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=5e-6)\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "epochs =100\n",
    "counter = 0\n",
    "\n",
    "global_instruction_metrices = []\n",
    "global_masked_token_metrices = []\n",
    "\n",
    "v_global_instruction_metrices = []\n",
    "v_global_masked_token_metrices = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    train_loop = tqdm(train_loader, leave=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    masked_token_predictions_all, masked_token_ground_truths_all = None, None\n",
    "    seq_predictions_all, seq_ground_truths_all = None, None\n",
    "    \n",
    "    # activate training mode\n",
    "    model.train()\n",
    "    for N,batch in enumerate(train_loop):\n",
    "\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        # token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        batch_mask_arr = batch ['mask_arr']\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids ,attention_mask = attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        token_prediction = torch.argmax(logits, axis=-1)\n",
    "\n",
    "        \n",
    "        batch_masks =   [ torch.flatten(bm.nonzero()).tolist()  for bm in batch_mask_arr]    # torch.flatten(batch ['mask_arr'].nonzero()).tolist()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        masked_token_prediction = [ token[batch_masks[t]].tolist() for t,token in enumerate(token_prediction) ]\n",
    "        masked_token_prediction = list(chain.from_iterable(masked_token_prediction))\n",
    "        \n",
    "        masked_token_ground_truth   = [ token[batch_masks[t]].tolist() for t,token in enumerate(labels) ]\n",
    "        masked_token_ground_truth = list(chain.from_iterable(masked_token_ground_truth))\n",
    "        \n",
    "\n",
    "\n",
    "        seq_predictions   = token_prediction.detach().cpu().numpy().flatten()\n",
    "        seq_ground_truths = labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        if N==0:\n",
    "\n",
    "            \n",
    "            masked_token_predictions_all         = masked_token_prediction\n",
    "            masked_token_ground_truths_all       = masked_token_ground_truth  \n",
    "\n",
    "\n",
    "            seq_predictions_all = seq_predictions\n",
    "            seq_ground_truths_all = seq_ground_truths\n",
    "            \n",
    "        else:\n",
    "\n",
    "            masked_token_predictions_all   = np.concatenate((masked_token_predictions_all, masked_token_prediction))\n",
    "            masked_token_ground_truths_all = np.concatenate((masked_token_ground_truths_all, masked_token_ground_truth))\n",
    "\n",
    "            seq_predictions_all = np.concatenate((seq_predictions_all, seq_predictions))\n",
    "            seq_ground_truths_all = np.concatenate((seq_ground_truths_all, seq_ground_truths))\n",
    "\n",
    "\n",
    "                # Compute loss\n",
    "        logits = logits.view(-1, logits.size(-1))  # [batch_size * seq_length, vocab_size]\n",
    "        labels = labels.view(-1)  # [batch_size * seq_length]\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        # Now, you can update the model's weights using the optimizer\n",
    "        optim.step()\n",
    "        # Zero gradients after updating the model's weights\n",
    "        optim.zero_grad()\n",
    "\n",
    "        train_loop.set_description(f'Epoch {epoch}')\n",
    "        train_loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    ###########################################\n",
    "    ###############  EVAL Validation  #########\n",
    "    ###########################################\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        v_masked_token_predictions_all, v_masked_token_ground_truths_all = None, None\n",
    "        v_seq_predictions_all, v_seq_ground_truths_all = None, None\n",
    "    \n",
    "    \n",
    "        validation_loop = tqdm(validation_loader, leave=True)\n",
    "        for N,v_batch in enumerate(validation_loop):\n",
    "            \n",
    "            \n",
    "            \n",
    "            v_input_ids = v_batch['input_ids'].to(device)\n",
    "            v_attention_mask = v_batch['attention_mask'].to(device)\n",
    "            v_mask_arr = v_batch ['mask_arr']\n",
    "            v_labels = v_batch['labels'].to(device)\n",
    "            # process\n",
    "            v_outputs = model(v_input_ids, attention_mask=v_attention_mask)\n",
    "\n",
    "\n",
    "            v_logits = v_outputs.logits\n",
    "\n",
    "        \n",
    "            v_token_prediction = torch.argmax(v_logits, axis=-1)\n",
    "\n",
    "                    \n",
    "\n",
    "            v_batch_masks =   [ torch.flatten(bm.nonzero()).tolist()  for bm in v_mask_arr]\n",
    "            \n",
    "            v_masked_token_prediction = [ token[v_batch_masks[t]].tolist() for t,token in enumerate(v_token_prediction) ]\n",
    "            v_masked_token_prediction = list(chain.from_iterable(v_masked_token_prediction))\n",
    "            \n",
    "            v_masked_token_ground_truth   = [ token[v_batch_masks[t]].tolist() for t,token in enumerate(v_labels) ]\n",
    "            v_masked_token_ground_truth = list(chain.from_iterable(v_masked_token_ground_truth))\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            #discard the padding tokens and just keep the non padding tokens for evaluation\n",
    "            v_seq_prediction = v_token_prediction.detach().cpu().numpy().flatten()\n",
    "            v_seq_ground_truth = v_labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "            filteredTokenPredictionWithoutPadding =[] \n",
    "            filteredTokenGTWithoutPadding = []\n",
    "            \n",
    "            for gi,g in enumerate(v_seq_ground_truth):\n",
    "                if g!=pad_token_id:\n",
    "                    filteredTokenGTWithoutPadding.append(v_seq_ground_truth [gi])\n",
    "                    filteredTokenPredictionWithoutPadding.append(v_seq_prediction[gi])\n",
    "\n",
    "            v_seq_ground_truth = filteredTokenGTWithoutPadding\n",
    "            v_seq_prediction = filteredTokenPredictionWithoutPadding\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            if N==0:\n",
    "\n",
    "                v_masked_token_predictions_all   = v_masked_token_prediction\n",
    "                v_masked_token_ground_truths_all = v_masked_token_ground_truth\n",
    "                \n",
    "                v_seq_predictions_all= v_seq_prediction\n",
    "                v_seq_ground_truths_all = v_seq_ground_truth\n",
    "\n",
    "        \n",
    "\n",
    "            else:\n",
    "\n",
    "                v_masked_token_predictions_all   = np.concatenate((v_masked_token_predictions_all, v_masked_token_prediction ))\n",
    "                v_masked_token_ground_truths_all = np.concatenate((v_masked_token_ground_truths_all, v_masked_token_ground_truth ))\n",
    "                \n",
    "                v_seq_predictions_all =np.concatenate((v_seq_predictions_all, v_seq_prediction ))\n",
    "                v_seq_ground_truths_all =np.concatenate((v_seq_ground_truths_all, v_seq_ground_truth ))\n",
    "                \n",
    "\n",
    "            \n",
    " \n",
    "\n",
    "        v_masked_token_accuracy = (accuracy_score(v_masked_token_ground_truths_all, v_masked_token_predictions_all))\n",
    "        v_masked_token_precision, v_masked_token_recall, v_masked_token_f1, _ = precision_recall_fscore_support(v_masked_token_ground_truths_all,v_masked_token_predictions_all,average='weighted')\n",
    "\n",
    "\n",
    "        v_seq_accuracy = (accuracy_score(v_seq_predictions_all, v_seq_ground_truths_all))\n",
    "        v_seq_precision, v_seq_recall, v_seq_f1, _ = precision_recall_fscore_support(v_seq_ground_truths_all,v_seq_predictions_all,average='weighted')\n",
    "\n",
    "        print(\"Validation: acc \",v_masked_token_accuracy,  \"   v_masked_token_ F1: \",v_masked_token_f1 ,\" V SEQ F1: \", v_seq_f1 , 'v_seq_accuracy' ,v_seq_accuracy)\n",
    "        \n",
    "\n",
    "        v_global_masked_token_metrices.append(v_masked_token_f1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./../../models/\"+EXPERIMENT_NAME+\"lama_model.ckpt\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
