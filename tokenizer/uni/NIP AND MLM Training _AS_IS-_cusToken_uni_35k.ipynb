{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499921/3274186680.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import sys,os\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from elftools.elf.segments import Segment\n",
    "from capstone import *\n",
    "from capstone.x86 import *\n",
    "\n",
    "import os\n",
    "import json \n",
    "\n",
    "import sys,os\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(1024, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=35000, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MAX_TOKEN_LEN = 1024\n",
    "BATCH_SIZE = 34\n",
    "epochs = 15\n",
    "\n",
    "EXPERIMENT_NAME = 'cusTokenizer_UNI_35k_ASIS'\n",
    "new_vocab_size = 35000\n",
    "\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction,BertForPreTraining,BertConfig,AutoModelForMaskedLM,get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast ,AutoModelForPreTraining\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"./../../models/\" + EXPERIMENT_NAME)\n",
    "print(tokenizer.pad_token) \n",
    "\n",
    "\n",
    "\n",
    "config = BertConfig.from_pretrained(\"mosaicml/mosaic-bert-base-seqlen-1024\")\n",
    "# Change max_position_embeddings to 1024 in the config\n",
    "config.max_position_embeddings = 1024\n",
    "# Load the model with the modified config\n",
    "model = BertForPreTraining(config)\n",
    "# Access and modify the positional embeddings\n",
    "# The model's `bert` attribute holds the BERT layers\n",
    "model_bert = model.bert  # This is the BERT model itself (the backbone)\n",
    "# Resize the position embeddings to accommodate the new max length (1024 tokens)\n",
    "model_bert.embeddings.position_embeddings = torch.nn.Embedding(1024, model_bert.config.hidden_size)\n",
    "# Optional: Initialize the new embeddings using the original ones for the first 512 positions\n",
    "with torch.no_grad():\n",
    "    model_bert.embeddings.position_embeddings.weight[:512, :] = model_bert.embeddings.position_embeddings.weight[:512, :]\n",
    "\n",
    "\n",
    "model.resize_token_embeddings(new_vocab_size)\n",
    "\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "Functions Count:  80000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "DATA_PATH = '/home/raisul/ANALYSED_DATA/tokenization_data_single_functions'\n",
    "\n",
    "TRAIN_DATA_PATH  ='/home/raisul/ANALYSED_DATA/tokenization_data_single_functions/train/'\n",
    "\n",
    "TEST_DATA_PATH   = '/home/raisul/ANALYSED_DATA/tokenization_data_single_functions/test/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_json_files = [os.path.join(TRAIN_DATA_PATH, f) for f in os.listdir(TRAIN_DATA_PATH) ]\n",
    "\n",
    "test_json_files = [os.path.join(TEST_DATA_PATH, f) for f in os.listdir(TEST_DATA_PATH) ]\n",
    "\n",
    "# disassembly_decimal disassembly_all_number_to_words disassembly_decimal\n",
    "data_key = \"disassembly_decimal\"\n",
    "\n",
    "print(len(train_json_files))\n",
    "def read_corpus(json_files):\n",
    "\n",
    "    all = []\n",
    "\n",
    "    for k, j_file in enumerate(json_files):\n",
    "        # if k>200:\n",
    "        #     break\n",
    "        try:\n",
    "\n",
    "            with open(j_file, 'r') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                funct = data[data_key]['input']\n",
    "                \n",
    "                all.append(funct)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    return all\n",
    "    \n",
    "\n",
    "\n",
    "train_text = read_corpus(train_json_files)\n",
    "test_text  = read_corpus(test_json_files)\n",
    "\n",
    "\n",
    "        \n",
    "# text = text[0:5000]\n",
    "print(\"Functions Count: \",len(train_text), '\\n')\n",
    "example = train_text[10]\n",
    "text = train_text + test_text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDBR64\n",
      "PUSH R15\n",
      "LEA RDI,[8270]\n",
      "PUSH R14\n",
      "PUSH R13\n",
      "PUSH R12\n",
      "PUSH RBP\n",
      "PUSH RBX\n",
      "SUB RSP,8\n",
      "CALL 4256\n",
      "MOVSXD RCX,dword ptr [17568]\n",
      "CMP ECX,1\n",
      "JLE 5555\n",
      "XOR R13D,R13D\n",
      "LEA RBX,[16576]\n",
      "LEA R14,[16480]\n",
      "LEA RBP,[8297]\n",
      "LEA R12,[16640]\n",
      "NOP dword ptr [RAX]\n",
      "XOR EAX,EAX\n",
      "MOV R15D,4294967295\n",
      "MOV EDX,987654321\n",
      "NOP dword ptr [RAX]\n",
      "MOV ESI,dword ptr [RBX + RAX*4]\n",
      "TEST ESI,ESI\n",
      "JNZ 5476\n",
      "MOV ESI,dword ptr [R12 + RAX*4]\n",
      "CMP EDX,ESI\n",
      "CMOVG R15D,EAX\n",
      "CMOVG EDX,ESI\n",
      "ADD RAX,1\n",
      "CMP RCX,RAX\n",
      "JNZ 5456\n",
      "MOVSXD RAX,R15D\n",
      "ADD dword ptr [16560],EDX\n",
      "MOV RSI,RBP\n",
      "MOV EDX,R15D\n",
      "MOV ECX,dword ptr [R14 + RAX*8]\n",
      "MOV R8D,dword ptr [R14 + RAX*8 + 4]\n",
      "MOV dword ptr [RBX + RAX*4],1\n",
      "XOR EAX,EAX\n",
      "MOV EDI,2\n",
      "ADD R13D,1\n",
      "CALL 4288\n",
      "MOV EDI,R15D\n",
      "CALL 5104\n",
      "MOVSXD RCX,dword ptr [17568]\n",
      "LEA EAX,[RCX + -1]\n",
      "CMP R13D,EAX\n",
      "JL 5440\n",
      "MOV EDX,dword ptr [16560]\n",
      "ADD RSP,8\n",
      "LEA RSI,[8321]\n",
      "XOR EAX,EAX\n",
      "POP RBX\n",
      "MOV EDI,2\n",
      "POP RBP\n",
      "POP R12\n",
      "POP R13\n",
      "POP R14\n",
      "POP R15\n",
      "JMP 4288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text[51].split(delim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll assign a 50% probability of using the genuine next sentence, and 50% probability of using another random sentence.\n",
    "\n",
    "To make this simpler, we'll create a *'bag'* of individual sentences to pull from when selecting a random sentence B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5312741 100000\n"
     ]
    }
   ],
   "source": [
    "delim = '\\n'\n",
    "bag = [instruction for instruction_cluster in text for instruction in instruction_cluster.split(delim)  if instruction!= '']\n",
    "bag_size = len(bag)\n",
    "print(bag_size , len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we create our 50/50 NIP training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "['ENDBR64', 'PUSH R12', 'LEA RSI,[4608]', 'MOV EDI,2', 'LEA R12,[8253]', 'PUSH RBP', 'LEA RBP,[8262]', 'PUSH RBX', 'XOR EBX,EBX', 'CALL 4224', 'JMP 4323', 'MOV RDI,RBP', 'ADD EBX,1', 'CALL 4208', 'CMP EBX,10000', 'JZ 4352', 'CMP EBX,100', 'JNZ 4304', 'MOV RDI,R12', 'MOV EBX,101', 'CALL 4208', 'MOV RDI,RBP', 'CALL 4208', 'JMP 4304', 'POP RBX', 'XOR EAX,EAX', 'POP RBP', 'POP R12', 'RET']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "history = []\n",
    "next_instruction = []\n",
    "label = []\n",
    "\n",
    "\n",
    "instruction_pages = []\n",
    "for instruction_cluster in text:\n",
    "    instructions = [\n",
    "        instruction for instruction in instruction_cluster.split(delim) if instruction != ''\n",
    "    ]\n",
    "\n",
    "    instruction_pages.append(instructions)\n",
    "\n",
    "        \n",
    "print(len(instruction_pages))\n",
    "print(instruction_pages[0])\n",
    "\n",
    "for instruction_page in instruction_pages:\n",
    "        # this is IsNextSentence\n",
    "        history.append(delim.join(instruction_page))\n",
    "        next_instruction.append(instruction_page[-1])\n",
    "        label.append(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now ready for tokenization, this time we truncate/pad each token to the same length of *512* tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(history, next_instruction, return_tensors='pt', \n",
    "                   max_length=MAX_TOKEN_LEN, truncation=True, padding=True)\n",
    "ground_truth = inputs.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the *token_type_ids* tensors have been built correctly (eg **1** indicating sentence B tokens) by checking the first instance of *token_type_ids*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the labels tensor is simply a clone of the input_ids tensor before masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T\n",
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we mask tokens in the input_ids tensor using the 15% probability for MLM - ensuring we don't mask CLS, SEP, or PAD tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 1024])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr.shape\n",
    "# inputs.input_ids.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now take the indices of each True value within each vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,\n",
       " 100000,\n",
       " [[0,\n",
       "   8,\n",
       "   13,\n",
       "   15,\n",
       "   22,\n",
       "   24,\n",
       "   43,\n",
       "   48,\n",
       "   54,\n",
       "   79,\n",
       "   81,\n",
       "   83,\n",
       "   88,\n",
       "   100,\n",
       "   104,\n",
       "   106,\n",
       "   109,\n",
       "   118,\n",
       "   120,\n",
       "   123,\n",
       "   167,\n",
       "   180,\n",
       "   186,\n",
       "   196,\n",
       "   201,\n",
       "   216,\n",
       "   217,\n",
       "   220,\n",
       "   225,\n",
       "   232,\n",
       "   234,\n",
       "   247,\n",
       "   256,\n",
       "   261,\n",
       "   262,\n",
       "   279,\n",
       "   288,\n",
       "   290,\n",
       "   314,\n",
       "   318,\n",
       "   351,\n",
       "   354,\n",
       "   375,\n",
       "   381,\n",
       "   384,\n",
       "   386,\n",
       "   398,\n",
       "   406,\n",
       "   416,\n",
       "   418,\n",
       "   424,\n",
       "   434,\n",
       "   452,\n",
       "   456,\n",
       "   462,\n",
       "   463,\n",
       "   469,\n",
       "   471,\n",
       "   478,\n",
       "   487,\n",
       "   500,\n",
       "   509,\n",
       "   528,\n",
       "   533,\n",
       "   540,\n",
       "   549,\n",
       "   550,\n",
       "   553,\n",
       "   555,\n",
       "   563,\n",
       "   573,\n",
       "   575,\n",
       "   584,\n",
       "   587,\n",
       "   588,\n",
       "   610,\n",
       "   611,\n",
       "   619,\n",
       "   637,\n",
       "   641,\n",
       "   646,\n",
       "   653,\n",
       "   686,\n",
       "   695,\n",
       "   701,\n",
       "   722,\n",
       "   724,\n",
       "   726,\n",
       "   738,\n",
       "   764,\n",
       "   765,\n",
       "   775,\n",
       "   777,\n",
       "   778,\n",
       "   784,\n",
       "   786,\n",
       "   802,\n",
       "   805,\n",
       "   808,\n",
       "   810,\n",
       "   815,\n",
       "   829,\n",
       "   834,\n",
       "   835,\n",
       "   844,\n",
       "   854,\n",
       "   861,\n",
       "   871,\n",
       "   880,\n",
       "   884,\n",
       "   901,\n",
       "   904,\n",
       "   916,\n",
       "   922,\n",
       "   923,\n",
       "   924,\n",
       "   926,\n",
       "   935,\n",
       "   938,\n",
       "   946,\n",
       "   955,\n",
       "   961,\n",
       "   972,\n",
       "   973,\n",
       "   987,\n",
       "   1003,\n",
       "   1007,\n",
       "   1008,\n",
       "   1011,\n",
       "   1019,\n",
       "   1022],\n",
       "  [12,\n",
       "   18,\n",
       "   22,\n",
       "   25,\n",
       "   35,\n",
       "   42,\n",
       "   46,\n",
       "   50,\n",
       "   52,\n",
       "   56,\n",
       "   58,\n",
       "   67,\n",
       "   80,\n",
       "   97,\n",
       "   98,\n",
       "   100,\n",
       "   112,\n",
       "   119,\n",
       "   122,\n",
       "   123,\n",
       "   139,\n",
       "   145,\n",
       "   152,\n",
       "   157,\n",
       "   158,\n",
       "   173,\n",
       "   177,\n",
       "   183,\n",
       "   185,\n",
       "   186,\n",
       "   208,\n",
       "   209,\n",
       "   211,\n",
       "   216,\n",
       "   219,\n",
       "   230,\n",
       "   231,\n",
       "   238,\n",
       "   243,\n",
       "   244,\n",
       "   254,\n",
       "   277,\n",
       "   278,\n",
       "   281,\n",
       "   297,\n",
       "   304,\n",
       "   313,\n",
       "   314,\n",
       "   317,\n",
       "   324,\n",
       "   350,\n",
       "   355,\n",
       "   356,\n",
       "   374,\n",
       "   382,\n",
       "   384,\n",
       "   385,\n",
       "   389,\n",
       "   398,\n",
       "   402,\n",
       "   410,\n",
       "   419,\n",
       "   433,\n",
       "   445,\n",
       "   459,\n",
       "   462,\n",
       "   467,\n",
       "   469,\n",
       "   477,\n",
       "   478,\n",
       "   479,\n",
       "   485,\n",
       "   487,\n",
       "   489,\n",
       "   494,\n",
       "   514,\n",
       "   515,\n",
       "   526,\n",
       "   528,\n",
       "   538,\n",
       "   539,\n",
       "   545,\n",
       "   548,\n",
       "   550,\n",
       "   558,\n",
       "   561,\n",
       "   562,\n",
       "   566,\n",
       "   588,\n",
       "   614,\n",
       "   620,\n",
       "   627,\n",
       "   643,\n",
       "   665,\n",
       "   671,\n",
       "   678,\n",
       "   679,\n",
       "   681,\n",
       "   687,\n",
       "   696,\n",
       "   702,\n",
       "   708,\n",
       "   717,\n",
       "   719,\n",
       "   720,\n",
       "   729,\n",
       "   747,\n",
       "   752,\n",
       "   753,\n",
       "   759,\n",
       "   760,\n",
       "   765,\n",
       "   768,\n",
       "   770,\n",
       "   771,\n",
       "   777,\n",
       "   793,\n",
       "   806,\n",
       "   813,\n",
       "   814,\n",
       "   822,\n",
       "   824,\n",
       "   826,\n",
       "   832,\n",
       "   840,\n",
       "   851,\n",
       "   866,\n",
       "   873,\n",
       "   874,\n",
       "   879,\n",
       "   881,\n",
       "   882,\n",
       "   894,\n",
       "   896,\n",
       "   912,\n",
       "   919,\n",
       "   926,\n",
       "   940,\n",
       "   944,\n",
       "   946,\n",
       "   971,\n",
       "   975,\n",
       "   976,\n",
       "   977,\n",
       "   981,\n",
       "   985,\n",
       "   989,\n",
       "   1004,\n",
       "   1008,\n",
       "   1013,\n",
       "   1014,\n",
       "   1020,\n",
       "   1021,\n",
       "   1023],\n",
       "  [17,\n",
       "   21,\n",
       "   28,\n",
       "   32,\n",
       "   40,\n",
       "   47,\n",
       "   69,\n",
       "   77,\n",
       "   78,\n",
       "   79,\n",
       "   80,\n",
       "   88,\n",
       "   94,\n",
       "   100,\n",
       "   101,\n",
       "   107,\n",
       "   114,\n",
       "   122,\n",
       "   123,\n",
       "   128,\n",
       "   139,\n",
       "   152,\n",
       "   154,\n",
       "   174,\n",
       "   200,\n",
       "   210,\n",
       "   211,\n",
       "   218,\n",
       "   232,\n",
       "   242,\n",
       "   251,\n",
       "   254,\n",
       "   269,\n",
       "   270,\n",
       "   271,\n",
       "   280,\n",
       "   287,\n",
       "   288,\n",
       "   301,\n",
       "   308,\n",
       "   312,\n",
       "   316,\n",
       "   331,\n",
       "   332,\n",
       "   337,\n",
       "   342,\n",
       "   349,\n",
       "   350,\n",
       "   351,\n",
       "   352,\n",
       "   358,\n",
       "   361,\n",
       "   365,\n",
       "   387,\n",
       "   388,\n",
       "   392,\n",
       "   393,\n",
       "   402,\n",
       "   406,\n",
       "   407,\n",
       "   412,\n",
       "   433,\n",
       "   450,\n",
       "   453,\n",
       "   466,\n",
       "   469,\n",
       "   483,\n",
       "   486,\n",
       "   495,\n",
       "   496,\n",
       "   499,\n",
       "   502,\n",
       "   526,\n",
       "   529,\n",
       "   533,\n",
       "   534,\n",
       "   536,\n",
       "   538,\n",
       "   541,\n",
       "   543,\n",
       "   547,\n",
       "   554,\n",
       "   558,\n",
       "   559,\n",
       "   564,\n",
       "   567,\n",
       "   569,\n",
       "   570,\n",
       "   584,\n",
       "   586,\n",
       "   587,\n",
       "   589,\n",
       "   592,\n",
       "   594,\n",
       "   598,\n",
       "   599,\n",
       "   600,\n",
       "   601,\n",
       "   610,\n",
       "   620,\n",
       "   634,\n",
       "   642,\n",
       "   651,\n",
       "   653,\n",
       "   661,\n",
       "   668,\n",
       "   672,\n",
       "   675,\n",
       "   678,\n",
       "   694,\n",
       "   695,\n",
       "   701,\n",
       "   706,\n",
       "   712,\n",
       "   720,\n",
       "   733,\n",
       "   742,\n",
       "   745,\n",
       "   746,\n",
       "   747,\n",
       "   750,\n",
       "   754,\n",
       "   764,\n",
       "   768,\n",
       "   772,\n",
       "   775,\n",
       "   781,\n",
       "   782,\n",
       "   783,\n",
       "   791,\n",
       "   804,\n",
       "   811,\n",
       "   813,\n",
       "   815,\n",
       "   820,\n",
       "   839,\n",
       "   844,\n",
       "   846,\n",
       "   850,\n",
       "   851,\n",
       "   855,\n",
       "   858,\n",
       "   866,\n",
       "   877,\n",
       "   879,\n",
       "   883,\n",
       "   885,\n",
       "   893,\n",
       "   895,\n",
       "   896,\n",
       "   921,\n",
       "   928,\n",
       "   945,\n",
       "   948,\n",
       "   955,\n",
       "   958,\n",
       "   960,\n",
       "   966,\n",
       "   971,\n",
       "   974,\n",
       "   986,\n",
       "   992,\n",
       "   996,\n",
       "   999,\n",
       "   1007,\n",
       "   1008,\n",
       "   1010,\n",
       "   1012,\n",
       "   1013,\n",
       "   1017,\n",
       "   1023]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (selection) , len(inputs.input_ids), selection[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then apply these indices to each row in input_ids, assigning each value at these indices a value of 103."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_labels = []\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    masked_labels.append(inputs.input_ids[i, selection[i]])\n",
    "    inputs.input_ids[i, selection[i]] = 103\n",
    "# masked_labels[0]\n",
    "inputs[\"mask_arr\"] = mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels', 'mask_arr'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `inputs` tensors are now ready, and we can begin building the model input pipeline for training. We first create a PyTorch dataset from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeditationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize our data using the `MeditationDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MeditationsDataset(inputs)\n",
    "# print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 20000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_dataset  = torch.utils.data.Subset(dataset, range(len(train_text)))\n",
    "validation_dataset = torch.utils.data.Subset(dataset, range(len(train_text) , len(dataset)))\n",
    "\n",
    "len(train_dataset) , len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And initialize the dataloader, which we'll be using to load our data into the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the training mode of our model, and initialize our optimizer (Adam with weighted decay - reduces chance of overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto the training loop, we'll train for a couple of epochs (change `epochs` to modify this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odict_keys(['loss', 'prediction_logits', 'seq_relationship_logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graph(training_data, validation_data , label ):\n",
    "\n",
    "    font_size = 10\n",
    "    x_labels = [ i for i in range(len(training_data)) ]\n",
    "\n",
    "    plt.ylabel(' F1 ',fontsize=font_size)\n",
    "    plt.plot(x_labels, training_data , 'r') \n",
    "    plt.plot(x_labels, validation_data , 'b') \n",
    "    plt.xlabel(\"Epoch\", fontsize=font_size)\n",
    "    plt.title(label,fontsize=font_size)\n",
    "    plt.legend(['Training', 'Validation'], loc='upper left') \n",
    "    \n",
    "    plt.savefig('./../../results/'+EXPERIMENT_NAME+label+'.pdf')\n",
    "    plt.show()\n",
    "    with open('./../../results/'+EXPERIMENT_NAME+label+'.json', 'w') as json_file:\n",
    "        json.dump([training_data, validation_data , label], json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raisul/anaconda3/envs/pytorch/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=3e-4 ,weight_decay=0.0001)\n",
    "\n",
    "# Number of training steps per epoch\n",
    "train_steps = len(train_loader)\n",
    "\n",
    "# Define the number of total training steps and warmup steps\n",
    "total_steps = train_steps * epochs\n",
    "warmup_steps = int(total_steps * 0.1)  # 10% of total steps as warmup\n",
    "\n",
    "# Scheduler setup\n",
    "scheduler = get_linear_schedule_with_warmup(optim,\n",
    "                                            num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 0/2353 [00:00<?, ?it/s]/tmp/ipykernel_1499921/81523791.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0:  15%|█▊          | 355/2353 [08:22<47:33,  1.43s/it, loss=1.14]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "counter = 0\n",
    "\n",
    "global_instruction_metrices = []\n",
    "global_masked_token_metrices = []\n",
    "\n",
    "v_global_instruction_metrices = []\n",
    "v_global_masked_token_metrices = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    train_loop = tqdm(train_loader, leave=True)\n",
    "    \n",
    "    \n",
    "    instruction_predictions_all, instruction_ground_truths_all = None, None\n",
    "    masked_token_predictions_all, masked_token_ground_truths_all = None, None\n",
    "    seq_predictions_all, seq_ground_truths_all = None, None\n",
    "    \n",
    "    # activate training mode\n",
    "    model.train()\n",
    "    for N,batch in enumerate(train_loop):\n",
    "\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        next_sentence_label = batch['next_sentence_label'].to(device)\n",
    "        batch_mask_arr = batch ['mask_arr']\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        next_sentence_label=next_sentence_label,\n",
    "                        labels=labels)\n",
    "\n",
    "\n",
    "        token_prediction = torch.argmax(outputs.prediction_logits, axis=-1)\n",
    "       \n",
    "\n",
    "\n",
    "        # batch_masks = selection [BATCH_SIZE*N : (BATCH_SIZE*(N+1))]\n",
    "        # print('batch_masks old: ',batch_masks)\n",
    "\n",
    "        # print(batch ['mask_arr'].shape) #torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        batch_masks =   [ torch.flatten(bm.nonzero()).tolist()  for bm in batch_mask_arr]    # torch.flatten(batch ['mask_arr'].nonzero()).tolist()\n",
    "        # print('batch_masks new: ',batch_masks)\n",
    "        \n",
    "        # print(\"BATCH_SIZE*N : (BATCH_SIZE*(N+1)): \",BATCH_SIZE*N , (BATCH_SIZE*(N+1)) )\n",
    "        # print(\"batch_masks:\",batch_masks)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        masked_token_prediction = [ token[batch_masks[t]].tolist() for t,token in enumerate(token_prediction) ]\n",
    "        masked_token_prediction = list(chain.from_iterable(masked_token_prediction))\n",
    "        \n",
    "        masked_token_ground_truth   = [ token[batch_masks[t]].tolist() for t,token in enumerate(labels) ]\n",
    "        masked_token_ground_truth = list(chain.from_iterable(masked_token_ground_truth))\n",
    "        \n",
    "\n",
    "        # print(token_prediction , token_ground_truth)\n",
    "\n",
    "        # token_prediction = token_prediction.detach().cpu().numpy().flatten()\n",
    "        # token_ground_truth = labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "        # print(\"token_prediction  : \", token_prediction)\n",
    "        # print(\"token_ground_truth: \", token_ground_truth)\n",
    "\n",
    "\n",
    "        seq_predictions   = token_prediction.detach().cpu().numpy().flatten()\n",
    "        seq_ground_truths = labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "        \n",
    "        instruction_prediction = torch.argmax(outputs.seq_relationship_logits, axis=-1)\n",
    "        instruction_prediction   = instruction_prediction.detach().cpu().numpy().flatten()\n",
    "        instruction_ground_truth = next_sentence_label.detach().cpu().numpy().flatten()\n",
    "        \n",
    "        if N==0:\n",
    "            instruction_predictions_all   = instruction_prediction\n",
    "            instruction_ground_truths_all = instruction_ground_truth\n",
    "            \n",
    "            masked_token_predictions_all         = masked_token_prediction\n",
    "            masked_token_ground_truths_all       = masked_token_ground_truth  \n",
    "\n",
    "\n",
    "            seq_predictions_all = seq_predictions\n",
    "            seq_ground_truths_all = seq_ground_truths\n",
    "            \n",
    "        else:\n",
    "            instruction_predictions_all   = np.concatenate((instruction_predictions_all, instruction_prediction))\n",
    "            instruction_ground_truths_all = np.concatenate((instruction_ground_truths_all, instruction_ground_truth))\n",
    "            \n",
    "            masked_token_predictions_all   = np.concatenate((masked_token_predictions_all, masked_token_prediction))\n",
    "            masked_token_ground_truths_all = np.concatenate((masked_token_ground_truths_all, masked_token_ground_truth))\n",
    "\n",
    "            seq_predictions_all = np.concatenate((seq_predictions_all, seq_predictions))\n",
    "            seq_ground_truths_all = np.concatenate((seq_ground_truths_all, seq_ground_truths))\n",
    "            \n",
    "\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "        # print relevant info to progress bar\n",
    "        train_loop.set_description(f'Epoch {epoch}')\n",
    "        train_loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    \n",
    "    instruction_accuracy = (accuracy_score(instruction_ground_truths_all,instruction_predictions_all))\n",
    "    instruction_precision, instruction_recall, instruction_f1, _ = precision_recall_fscore_support(instruction_ground_truths_all,instruction_predictions_all, average='binary')\n",
    "    \n",
    "    masked_token_accuracy = (accuracy_score(masked_token_ground_truths_all, masked_token_predictions_all))\n",
    "    masked_token_precision, masked_token_recall, masked_token_f1, _ = precision_recall_fscore_support(masked_token_ground_truths_all,masked_token_predictions_all,average='weighted')\n",
    "\n",
    "    seq_precision, seq_recall, seq_f1, _ = precision_recall_fscore_support(seq_ground_truths_all,seq_predictions_all,average='weighted')\n",
    "    \n",
    "    print(\"Training: \",  ' Instruction f1: ', instruction_f1 , '  Masked Token f1: ',masked_token_f1 , ' masked_token_precision: ', masked_token_precision, ' masked_token_recall: ', masked_token_recall, ' masked_token_accuracy ', masked_token_accuracy,\"    SEQ F1\",seq_f1)\n",
    "    global_instruction_metrices.append(instruction_f1)\n",
    "    global_masked_token_metrices.append( masked_token_f1) \n",
    "\n",
    "    ###########################################\n",
    "    ###############  EVAL Validation  #########\n",
    "    ###########################################\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "#         v_predictions_all, v_ground_truths_all = None, None\n",
    "        \n",
    "        v_instruction_predictions_all, v_instruction_ground_truths_all = None, None\n",
    "        v_masked_token_predictions_all, v_masked_token_ground_truths_all = None, None\n",
    "        v_seq_predictions_all, v_seq_ground_truths_all = None, None\n",
    "    \n",
    "    \n",
    "        validation_loop = tqdm(validation_loader, leave=True)\n",
    "        for N,v_batch in enumerate(validation_loop):\n",
    "            \n",
    "            \n",
    "            \n",
    "            v_input_ids = v_batch['input_ids'].to(device)\n",
    "            v_token_type_ids = v_batch['token_type_ids'].to(device)\n",
    "            v_attention_mask = v_batch['attention_mask'].to(device)\n",
    "            v_next_sentence_label = v_batch['next_sentence_label'].to(device)\n",
    "            v_mask_arr = v_batch ['mask_arr']\n",
    "            v_labels = v_batch['labels'].to(device)\n",
    "            # process\n",
    "            v_outputs = model(v_input_ids, attention_mask=v_attention_mask,\n",
    "                            token_type_ids=v_token_type_ids,\n",
    "                            next_sentence_label=v_next_sentence_label,\n",
    "                            labels=v_labels)\n",
    "        \n",
    "            v_token_prediction = torch.argmax(v_outputs.prediction_logits, axis=-1)\n",
    "\n",
    "                    \n",
    "\n",
    "            v_batch_masks =   [ torch.flatten(bm.nonzero()).tolist()  for bm in v_mask_arr]\n",
    "            \n",
    "            v_masked_token_prediction = [ token[v_batch_masks[t]].tolist() for t,token in enumerate(v_token_prediction) ]\n",
    "            v_masked_token_prediction = list(chain.from_iterable(v_masked_token_prediction))\n",
    "            \n",
    "            v_masked_token_ground_truth   = [ token[v_batch_masks[t]].tolist() for t,token in enumerate(v_labels) ]\n",
    "            v_masked_token_ground_truth = list(chain.from_iterable(v_masked_token_ground_truth))\n",
    "    \n",
    "            \n",
    "            \n",
    "\n",
    "            v_seq_prediction = v_token_prediction.detach().cpu().numpy().flatten()\n",
    "            v_seq_ground_truth = v_labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            # token_prediction = [ token[batch_masks[t]].tolist() for t,token in enumerate(token_prediction) ]\n",
    "            # token_prediction = list(chain.from_iterable(token_prediction))\n",
    "            \n",
    "            # token_ground_truth   = [ token[batch_masks[t]].tolist() for t,token in enumerate(labels) ]\n",
    "            # token_ground_truth = list(chain.from_iterable(token_ground_truth))\n",
    "\n",
    "            \n",
    "            v_instruction_prediction = torch.argmax(v_outputs.seq_relationship_logits, axis=-1)\n",
    "            v_instruction_prediction   = v_instruction_prediction.detach().cpu().numpy().flatten()\n",
    "            v_instruction_ground_truth = v_next_sentence_label.detach().cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "            if N==0:\n",
    "                v_instruction_predictions_all   = v_instruction_prediction\n",
    "                v_instruction_ground_truths_all = v_instruction_ground_truth\n",
    "\n",
    "                v_masked_token_predictions_all   = v_masked_token_prediction\n",
    "                v_masked_token_ground_truths_all = v_masked_token_ground_truth\n",
    "                \n",
    "                v_seq_predictions_all= v_seq_prediction\n",
    "                v_seq_ground_truths_all = v_seq_ground_truth\n",
    "\n",
    "        \n",
    "\n",
    "            else:\n",
    "                v_instruction_predictions_all   = np.concatenate((v_instruction_predictions_all, v_instruction_prediction))\n",
    "                v_instruction_ground_truths_all = np.concatenate((v_instruction_ground_truths_all, v_instruction_ground_truth))\n",
    "\n",
    "                v_masked_token_predictions_all   = np.concatenate((v_masked_token_predictions_all, v_masked_token_prediction ))\n",
    "                v_masked_token_ground_truths_all = np.concatenate((v_masked_token_ground_truths_all, v_masked_token_ground_truth ))\n",
    "                \n",
    "                v_seq_predictions_all =np.concatenate((v_seq_predictions_all, v_seq_prediction ))\n",
    "                v_seq_ground_truths_all =np.concatenate((v_seq_ground_truths_all, v_seq_ground_truth ))\n",
    "                \n",
    "\n",
    "            \n",
    "\n",
    "        v_instruction_accuracy = (accuracy_score(v_instruction_ground_truths_all,v_instruction_predictions_all))\n",
    "        v_instruction_precision, v_instruction_recall, v_instruction_f1, _ = precision_recall_fscore_support(v_instruction_ground_truths_all,v_instruction_predictions_all, average='binary')\n",
    "\n",
    "\n",
    "        v_masked_token_accuracy = (accuracy_score(v_masked_token_ground_truths_all, v_masked_token_predictions_all))\n",
    "        v_masked_token_precision, v_masked_token_recall, v_masked_token_f1, _ = precision_recall_fscore_support(v_masked_token_ground_truths_all,v_masked_token_predictions_all,average='weighted')\n",
    "\n",
    "\n",
    "        v_seq_accuracy = (accuracy_score(v_seq_predictions_all, v_seq_ground_truths_all))\n",
    "        v_seq_precision, v_seq_recall, v_seq_f1, _ = precision_recall_fscore_support(v_seq_ground_truths_all,v_seq_predictions_all,average='weighted')\n",
    "    \n",
    "        print(\"Validation: \", \"Instruction F1: \", v_instruction_f1,  \"   v_masked_token_ F1: \",v_masked_token_f1,'v_seq_accuracy: ',v_seq_accuracy,' v_masked_token_precision : ',v_masked_token_precision,'v_masked_token_recall:', v_masked_token_recall,\" V SEQ F1: \", v_seq_f1)\n",
    "        \n",
    "        v_global_instruction_metrices.append(v_instruction_f1)\n",
    "        v_global_masked_token_metrices.append(v_masked_token_f1) \n",
    "\n",
    "    \n",
    "    plot_graph(global_instruction_metrices, v_global_instruction_metrices, 'Next Sentence Prediction Scores')\n",
    "    plot_graph(global_masked_token_metrices, v_global_masked_token_metrices, 'Masked Token Prediction Scores')\n",
    "    model.save_pretrained(\"./../../models/\"+EXPERIMENT_NAME+\"_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0,1,2,3,4,5]\n",
    "a[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
