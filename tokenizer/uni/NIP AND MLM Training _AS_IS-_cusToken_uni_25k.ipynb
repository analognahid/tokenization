{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import sys,os\n",
    "from elftools.elf.elffile import ELFFile\n",
    "from elftools.elf.segments import Segment\n",
    "from capstone import *\n",
    "from capstone.x86 import *\n",
    "\n",
    "import os\n",
    "import json \n",
    "\n",
    "import sys,os\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction,BertForPreTraining\n",
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"./../../models/cusTokenizer_UNI_25k_ASIS\")\n",
    "print(tokenizer.pad_token) \n",
    "# model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "model = BertForPreTraining.from_pretrained('bert-base-uncased')\n",
    "MAX_TOKEN_LEN = 512\n",
    "BATCH_SIZE = 256 +50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81107\n",
      "Functions Count:  81107 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "DATA_PATH = '/home/raisul/ANALYSED_DATA/tokenization_data_single_functions'\n",
    "\n",
    "TRAIN_DATA_PATH  ='/home/raisul/ANALYSED_DATA/tokenization_data_single_functions/train/'\n",
    "\n",
    "TEST_DATA_PATH   = '/home/raisul/ANALYSED_DATA/tokenization_data_single_functions/test/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_json_files = [os.path.join(TRAIN_DATA_PATH, f) for f in os.listdir(TRAIN_DATA_PATH) ]\n",
    "\n",
    "test_json_files = [os.path.join(TEST_DATA_PATH, f) for f in os.listdir(TEST_DATA_PATH) ]\n",
    "\n",
    "# disassembly_decimal disassembly_all_number_to_words disassembly_decimal\n",
    "data_key = \"disassembly_decimal\"\n",
    "\n",
    "print(len(train_json_files))\n",
    "def read_corpus(json_files):\n",
    "\n",
    "    all = []\n",
    "\n",
    "    for k, j_file in enumerate(json_files):\n",
    "        # if k>20:\n",
    "        #     break\n",
    "        try:\n",
    "\n",
    "            with open(j_file, 'r') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                funct = data[data_key]['input']\n",
    "                \n",
    "                all.append(funct)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    return all\n",
    "    \n",
    "\n",
    "\n",
    "train_text = read_corpus(train_json_files)\n",
    "test_text  = read_corpus(test_json_files)\n",
    "\n",
    "\n",
    "        \n",
    "# text = text[0:5000]\n",
    "print(\"Functions Count: \",len(train_text), '\\n')\n",
    "example = train_text[10]\n",
    "text = train_text + test_text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDBR64\n",
      "SUB RSP,24\n",
      "LEA RSI,[8196]\n",
      "MOV EDI,2\n",
      "MOV RAX,qword ptr FS:[40]\n",
      "MOV qword ptr [RSP + 8],RAX\n",
      "XOR EAX,EAX\n",
      "CALL 4224\n",
      "LEA RSI,[RSP + 4]\n",
      "LEA RDI,[8221]\n",
      "XOR EAX,EAX\n",
      "CALL 4240\n",
      "MOV EAX,dword ptr [RSP + 4]\n",
      "MOV EDI,2\n",
      "LEA RSI,[8220]\n",
      "IMUL EDX,EAX,111\n",
      "LEA ECX,[RAX + RAX*2]\n",
      "IMUL EAX,EAX,1111\n",
      "LEA EDX,[RDX + RCX*4]\n",
      "ADD EDX,EAX\n",
      "XOR EAX,EAX\n",
      "CALL 4224\n",
      "MOV RAX,qword ptr [RSP + 8]\n",
      "SUB RAX,qword ptr FS:[40]\n",
      "JNZ 4379\n",
      "XOR EAX,EAX\n",
      "ADD RSP,24\n",
      "RET\n",
      "CALL 4208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text[51].split(delim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll assign a 50% probability of using the genuine next sentence, and 50% probability of using another random sentence.\n",
    "\n",
    "To make this simpler, we'll create a *'bag'* of individual sentences to pull from when selecting a random sentence B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2896720 101107\n"
     ]
    }
   ],
   "source": [
    "delim = '\\n'\n",
    "bag = [instruction for instruction_cluster in text for instruction in instruction_cluster.split(delim)  if instruction!= '']\n",
    "bag_size = len(bag)\n",
    "print(bag_size , len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we create our 50/50 NIP training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101107\n",
      "['ENDBR64', 'PUSH R12', 'LEA RSI,[8200]', 'MOV EDI,2', 'PUSH RBP', 'PUSH RBX', 'SUB RSP,32', 'MOV RAX,qword ptr FS:[40]', 'MOV qword ptr [RSP + 24],RAX', 'XOR EAX,EAX', 'CALL 4224', 'LEA RCX,[RSP + 16]', 'LEA RDX,[RSP + 12]', 'XOR EAX,EAX', 'LEA RSI,[RSP + 8]', 'LEA R8,[RSP + 20]', 'LEA RDI,[8246]', 'CALL 4240', 'MOV EBX,dword ptr [RSP + 20]', 'MOV R12D,dword ptr [RSP + 12]', 'LEA RSI,[8258]', 'MOV EBP,dword ptr [RSP + 8]', 'MOV EAX,dword ptr [RSP + 16]', 'MOV EDI,2', 'IMUL EBP,EBX', 'IMUL EAX,R12D', 'IMUL EBX,R12D', 'ADD EBP,EAX', 'XOR EAX,EAX', 'CALL 4224', 'XOR EAX,EAX', 'MOV ECX,EBX', 'MOV EDX,EBP', 'LEA RSI,[8252]', 'MOV EDI,2', 'CALL 4224', 'MOV RAX,qword ptr [RSP + 24]', 'SUB RAX,qword ptr FS:[40]', 'JNZ 4434', 'ADD RSP,32', 'XOR EAX,EAX', 'POP RBX', 'POP RBP', 'POP R12', 'RET', 'CALL 4208']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "history = []\n",
    "next_instruction = []\n",
    "label = []\n",
    "\n",
    "\n",
    "instruction_pages = []\n",
    "for instruction_cluster in text:\n",
    "    instructions = [\n",
    "        instruction for instruction in instruction_cluster.split(delim) if instruction != ''\n",
    "    ]\n",
    "\n",
    "    instruction_pages.append(instructions)\n",
    "    # if len(instructions)>page_len:\n",
    "        \n",
    "    #     for i in range(0,len(instructions),page_len):\n",
    "    #         instruction_pages.append(instructions[i:i+page_len])\n",
    "        \n",
    "print(len(instruction_pages))\n",
    "print(instruction_pages[0])\n",
    "\n",
    "for instruction_page in instruction_pages:\n",
    "    \n",
    "#     instructions = [\n",
    "#         instruction for instruction in instruction_page.split(';') if instruction != ''\n",
    "#     ]\n",
    "    \n",
    "    \n",
    "#     num_instructions = len(instruction_page)\n",
    "    \n",
    "    \n",
    "\n",
    "#     start = random.randint(0, num_instructions-2)\n",
    "    # 50/50 whether is IsNextSentence or NotNextSentence\n",
    "    if random.random() >= 0.5:\n",
    "        # this is IsNextSentence\n",
    "        history.append(delim.join(instruction_page[:-1]))\n",
    "        next_instruction.append(instruction_page[-1])\n",
    "        label.append(0)\n",
    "    else:\n",
    "        index = random.randint(0, bag_size-1)\n",
    "        # this is NotNextSentence\n",
    "        history.append(delim.join(instruction_page[:-1]))\n",
    "        next_instruction.append(bag[index])\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101107\n",
      "1\n",
      "-> ENDBR64\n",
      "PUSH R12\n",
      "LEA RSI,[8200]\n",
      "MOV EDI,2\n",
      "PUSH RBP\n",
      "PUSH RBX\n",
      "SUB RSP,32\n",
      "MOV RAX,qword ptr FS:[40]\n",
      "MOV qword ptr [RSP + 24],RAX\n",
      "XOR EAX,EAX\n",
      "CALL 4224\n",
      "LEA RCX,[RSP + 16]\n",
      "LEA RDX,[RSP + 12]\n",
      "XOR EAX,EAX\n",
      "LEA RSI,[RSP + 8]\n",
      "LEA R8,[RSP + 20]\n",
      "LEA RDI,[8246]\n",
      "CALL 4240\n",
      "MOV EBX,dword ptr [RSP + 20]\n",
      "MOV R12D,dword ptr [RSP + 12]\n",
      "LEA RSI,[8258]\n",
      "MOV EBP,dword ptr [RSP + 8]\n",
      "MOV EAX,dword ptr [RSP + 16]\n",
      "MOV EDI,2\n",
      "IMUL EBP,EBX\n",
      "IMUL EAX,R12D\n",
      "IMUL EBX,R12D\n",
      "ADD EBP,EAX\n",
      "XOR EAX,EAX\n",
      "CALL 4224\n",
      "XOR EAX,EAX\n",
      "MOV ECX,EBX\n",
      "MOV EDX,EBP\n",
      "LEA RSI,[8252]\n",
      "MOV EDI,2\n",
      "CALL 4224\n",
      "MOV RAX,qword ptr [RSP + 24]\n",
      "SUB RAX,qword ptr FS:[40]\n",
      "JNZ 4434\n",
      "ADD RSP,32\n",
      "XOR EAX,EAX\n",
      "POP RBX\n",
      "POP RBP\n",
      "POP R12\n",
      "RET \n",
      "\n",
      "#  ENDBR64 \n",
      "\n",
      "0\n",
      "-> ENDBR64\n",
      "MOV EAX,dword ptr [16448]\n",
      "LEA RCX,[16480]\n",
      "LEA EDX,[RAX + 1]\n",
      "ADD EAX,2\n",
      "MOVSXD RSI,EDX\n",
      "MOV dword ptr [16448],EDX\n",
      "MOV dword ptr [RCX + RSI*4],EDI\n",
      "CMP EAX,2\n",
      "JA 4839\n",
      "RET\n",
      "MOVSXD RDX,EDX\n",
      "MOV dword ptr [RCX + RSI*4],EDI\n",
      "MOV dword ptr [RCX + RDX*4],R8D\n",
      "LEA EDX,[RAX + 1]\n",
      "CMP EDX,2\n",
      "JBE 4860\n",
      "MOV EDI,dword ptr [RCX + RSI*4]\n",
      "MOV EDX,EAX\n",
      "MOV EAX,EDX\n",
      "SHR EAX,31\n",
      "ADD EAX,EDX\n",
      "SAR EAX,1\n",
      "MOVSXD RSI,EAX\n",
      "MOV R8D,dword ptr [RCX + RSI*4]\n",
      "CMP R8D,EDI\n",
      "JL 4816 \n",
      "\n",
      "#  RET \n",
      "\n",
      "0\n",
      "-> ENDBR64\n",
      "PUSH RBP\n",
      "LEA RBP,[8231]\n",
      "XOR EAX,EAX\n",
      "MOV ESI,2\n",
      "PUSH RBX\n",
      "MOV RDI,RBP\n",
      "SUB RSP,8\n",
      "CALL 4384\n",
      "TEST EAX,EAX\n",
      "JS 4499\n",
      "MOV EBX,EAX\n",
      "MOV RDX,RBP\n",
      "MOV EDI,2\n",
      "XOR EAX,EAX\n",
      "LEA RSI,[8267]\n",
      "CALL 4368\n",
      "MOV EDI,EBX\n",
      "CALL 4784\n",
      "MOV EDI,EBX\n",
      "CALL 4352\n",
      "XOR EAX,EAX\n",
      "ADD RSP,8\n",
      "POP RBX\n",
      "POP RBP\n",
      "RET\n",
      "CALL 4288\n",
      "MOV EDI,dword ptr [RAX]\n",
      "CALL 4400\n",
      "LEA RSI,[8253]\n",
      "MOV EDI,2\n",
      "MOV RDX,RAX\n",
      "XOR EAX,EAX\n",
      "CALL 4368\n",
      "OR EAX,4294967295 \n",
      "\n",
      "#  JMP 4492 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(label))\n",
    "for i in range(3):\n",
    "    print(label[i])\n",
    "    print('->',history[i] , '\\n')\n",
    "    print('# ',next_instruction[i] , '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is now ready for tokenization, this time we truncate/pad each token to the same length of *512* tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(history, next_instruction, return_tensors='pt', \n",
    "                   max_length=MAX_TOKEN_LEN, truncation=True, padding=True)\n",
    "ground_truth = inputs.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the *token_type_ids* tensors have been built correctly (eg **1** indicating sentence B tokens) by checking the first instance of *token_type_ids*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([617998, 113])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs.input_ids.shape)\n",
    "inputs.token_type_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **0** tokens following our sentence B tokens correspond to *PAD* tokens.\n",
    "\n",
    "Alongside this, we need to create a *labels* tensor too - which corresponds to the values contained within our `label` variable. Our *labels* tensor must be a *LongTensor*, and we will need to transpose the tensor so that it matches our other tensors' dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the labels tensor is simply a clone of the input_ids tensor before masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   3,    6,   18,   60,  105,  642,   26,    4,    6,   38,   14,   15,\n",
       "         965, 6924,    4,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "           2,    2,    2,    2,    2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we mask tokens in the input_ids tensor using the 15% probability for MLM - ensuring we don't mask CLS, SEP, or PAD tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([617998, 113])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_arr.shape\n",
    "# inputs.input_ids.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now take the indices of each True value within each vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617998,\n",
       " 617998,\n",
       " [[3,\n",
       "   4,\n",
       "   10,\n",
       "   12,\n",
       "   14,\n",
       "   35,\n",
       "   36,\n",
       "   40,\n",
       "   55,\n",
       "   57,\n",
       "   60,\n",
       "   64,\n",
       "   77,\n",
       "   87,\n",
       "   95,\n",
       "   101,\n",
       "   104,\n",
       "   106,\n",
       "   109,\n",
       "   112],\n",
       "  [6, 13, 16, 17, 30, 38, 57, 66, 68, 71, 73, 76, 82, 101, 110],\n",
       "  [2, 6, 11, 16, 28, 29, 30, 31, 46, 52, 75, 76, 92, 99, 100, 108]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (selection) , len(inputs.input_ids), selection[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then apply these indices to each row in input_ids, assigning each value at these indices a value of 103."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 58,  17, 111,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[0][selection[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_labels = []\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    masked_labels.append(inputs.input_ids[i, selection[i]])\n",
    "    inputs.input_ids[i, selection[i]] = 103\n",
    "# masked_labels[0]\n",
    "inputs[\"mask_arr\"] = mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels', 'mask_arr'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `inputs` tensors are now ready, and we can begin building the model input pipeline for training. We first create a PyTorch dataset from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeditationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize our data using the `MeditationDataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:283\u001b[0m, in \u001b[0;36mBatchEncoding.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m MeditationsDataset(inputs)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:285\u001b[0m, in \u001b[0;36mBatchEncoding.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[item]\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = MeditationsDataset(inputs)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617998\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 81107) range(81107, 617998)\n"
     ]
    }
   ],
   "source": [
    "print( range(len(train_text)), range(len(train_text) , len(dataset)  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (4292758200.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[25], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    validation_dataset = torch.utils.data.Subset(dataset, range(len(train_text)) , len(dataset)))\u001b[0m\n\u001b[0m                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "train_data_portion =  len(train_text)/(len(train_text) + len( test_text) )\n",
    "print(train_data_portion ,(len(train_text) + len( test_text) ))\n",
    "\n",
    "train_size = int(train_data_portion * len(dataset))\n",
    "validation_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset  = torch.utils.data.Subset(dataset, range(len(train_text)))\n",
    "validation_dataset = torch.utils.data.Subset(dataset, range(train_size , len(dataset)))\n",
    "\n",
    "train_size, len(train_dataset) , len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And initialize the dataloader, which we'll be using to load our data into the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader      = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto setting up the training loop. First we setup GPU/CPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the training mode of our model, and initialize our optimizer (Adam with weighted decay - reduces chance of overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support , accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can move onto the training loop, we'll train for a couple of epochs (change `epochs` to modify this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odict_keys(['loss', 'prediction_logits', 'seq_relationship_logits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graph(training_data, validation_data , label ):\n",
    "\n",
    "    font_size = 10\n",
    "    x_labels = [ i for i in range(len(training_data)) ]\n",
    "\n",
    "    plt.ylabel(' F1 ',fontsize=font_size)\n",
    "    plt.plot(x_labels, training_data , 'r') \n",
    "    plt.plot(x_labels, validation_data , 'b') \n",
    "    plt.xlabel(\"Epoch\", fontsize=font_size)\n",
    "    plt.title(label,fontsize=font_size)\n",
    "    plt.legend(['Training', 'Validation'], loc='upper left') \n",
    "    \n",
    "    plt.savefig('./../results/'+label+'.pdf')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm  # for our progress bar\n",
    "from itertools import chain\n",
    "\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=5e-6)\n",
    "\n",
    "\n",
    "\n",
    "epochs =1000\n",
    "counter = 0\n",
    "\n",
    "global_instruction_metrices = []\n",
    "global_masked_token_metrices = []\n",
    "\n",
    "v_global_instruction_metrices = []\n",
    "v_global_masked_token_metrices = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    train_loop = tqdm(train_loader, leave=True)\n",
    "    \n",
    "    \n",
    "    instruction_predictions_all, instruction_ground_truths_all = None, None\n",
    "    masked_token_predictions_all, masked_token_ground_truths_all = None, None\n",
    "    seq_predictions_all, seq_ground_truths_all = None, None\n",
    "    \n",
    "    # activate training mode\n",
    "    model.train()\n",
    "    for N,batch in enumerate(train_loop):\n",
    "\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        next_sentence_label = batch['next_sentence_label'].to(device)\n",
    "        batch_mask_arr = batch ['mask_arr']\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        next_sentence_label=next_sentence_label,\n",
    "                        labels=labels)\n",
    "\n",
    "\n",
    "        token_prediction = torch.argmax(outputs.prediction_logits, axis=-1)\n",
    "       \n",
    "\n",
    "\n",
    "        # batch_masks = selection [BATCH_SIZE*N : (BATCH_SIZE*(N+1))]\n",
    "        # print('batch_masks old: ',batch_masks)\n",
    "\n",
    "        # print(batch ['mask_arr'].shape) #torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "        batch_masks =   [ torch.flatten(bm.nonzero()).tolist()  for bm in batch_mask_arr]    # torch.flatten(batch ['mask_arr'].nonzero()).tolist()\n",
    "        # print('batch_masks new: ',batch_masks)\n",
    "        \n",
    "        # print(\"BATCH_SIZE*N : (BATCH_SIZE*(N+1)): \",BATCH_SIZE*N , (BATCH_SIZE*(N+1)) )\n",
    "        # print(\"batch_masks:\",batch_masks)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        masked_token_prediction = [ token[batch_masks[t]].tolist() for t,token in enumerate(token_prediction) ]\n",
    "        masked_token_prediction = list(chain.from_iterable(masked_token_prediction))\n",
    "        \n",
    "        masked_token_ground_truth   = [ token[batch_masks[t]].tolist() for t,token in enumerate(labels) ]\n",
    "        masked_token_ground_truth = list(chain.from_iterable(masked_token_ground_truth))\n",
    "        \n",
    "\n",
    "        # print(token_prediction , token_ground_truth)\n",
    "\n",
    "        # token_prediction = token_prediction.detach().cpu().numpy().flatten()\n",
    "        # token_ground_truth = labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "        # print(\"token_prediction  : \", token_prediction)\n",
    "        # print(\"token_ground_truth: \", token_ground_truth)\n",
    "\n",
    "\n",
    "        seq_predictions   = token_prediction.detach().cpu().numpy().flatten()\n",
    "        seq_ground_truths = labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "        \n",
    "        instruction_prediction = torch.argmax(outputs.seq_relationship_logits, axis=-1)\n",
    "        instruction_prediction   = instruction_prediction.detach().cpu().numpy().flatten()\n",
    "        instruction_ground_truth = next_sentence_label.detach().cpu().numpy().flatten()\n",
    "        \n",
    "        if N==0:\n",
    "            instruction_predictions_all   = instruction_prediction\n",
    "            instruction_ground_truths_all = instruction_ground_truth\n",
    "            \n",
    "            masked_token_predictions_all         = masked_token_prediction\n",
    "            masked_token_ground_truths_all       = masked_token_ground_truth  \n",
    "\n",
    "\n",
    "            seq_predictions_all = seq_predictions\n",
    "            seq_ground_truths_all = seq_ground_truths\n",
    "            \n",
    "        else:\n",
    "            instruction_predictions_all   = np.concatenate((instruction_predictions_all, instruction_prediction))\n",
    "            instruction_ground_truths_all = np.concatenate((instruction_ground_truths_all, instruction_ground_truth))\n",
    "            \n",
    "            masked_token_predictions_all   = np.concatenate((masked_token_predictions_all, masked_token_prediction))\n",
    "            masked_token_ground_truths_all = np.concatenate((masked_token_ground_truths_all, masked_token_ground_truth))\n",
    "\n",
    "            seq_predictions_all = np.concatenate((seq_predictions_all, seq_predictions))\n",
    "            seq_ground_truths_all = np.concatenate((seq_ground_truths_all, seq_ground_truths))\n",
    "            \n",
    "\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        train_loop.set_description(f'Epoch {epoch}')\n",
    "        train_loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    \n",
    "    instruction_accuracy = (accuracy_score(instruction_ground_truths_all,instruction_predictions_all))\n",
    "    instruction_precision, instruction_recall, instruction_f1, _ = precision_recall_fscore_support(instruction_ground_truths_all,instruction_predictions_all, average='binary')\n",
    "    \n",
    "    masked_token_accuracy = (accuracy_score(masked_token_ground_truths_all, masked_token_predictions_all))\n",
    "    masked_token_precision, masked_token_recall, masked_token_f1, _ = precision_recall_fscore_support(masked_token_ground_truths_all,masked_token_predictions_all,average='weighted')\n",
    "\n",
    "    seq_precision, seq_recall, seq_f1, _ = precision_recall_fscore_support(seq_ground_truths_all,seq_predictions_all,average='weighted')\n",
    "    \n",
    "    print(\"Training: \",  ' Instruction f1: ', instruction_f1 , '  Masked Token f1',masked_token_f1 , \"    SEQ F1\",seq_f1)\n",
    "    global_instruction_metrices.append(instruction_f1)\n",
    "    global_masked_token_metrices.append( masked_token_f1) \n",
    "\n",
    "    ###########################################\n",
    "    ###############  EVAL Validation  #########\n",
    "    ###########################################\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "#         v_predictions_all, v_ground_truths_all = None, None\n",
    "        \n",
    "        v_instruction_predictions_all, v_instruction_ground_truths_all = None, None\n",
    "        v_masked_token_predictions_all, v_masked_token_ground_truths_all = None, None\n",
    "        v_seq_predictions_all, v_seq_ground_truths_all = None, None\n",
    "    \n",
    "    \n",
    "        validation_loop = tqdm(validation_loader, leave=True)\n",
    "        for N,v_batch in enumerate(validation_loop):\n",
    "            \n",
    "            \n",
    "            \n",
    "            v_input_ids = v_batch['input_ids'].to(device)\n",
    "            v_token_type_ids = v_batch['token_type_ids'].to(device)\n",
    "            v_attention_mask = v_batch['attention_mask'].to(device)\n",
    "            v_next_sentence_label = v_batch['next_sentence_label'].to(device)\n",
    "            v_mask_arr = v_batch ['mask_arr']\n",
    "            v_labels = v_batch['labels'].to(device)\n",
    "            # process\n",
    "            v_outputs = model(v_input_ids, attention_mask=v_attention_mask,\n",
    "                            token_type_ids=v_token_type_ids,\n",
    "                            next_sentence_label=v_next_sentence_label,\n",
    "                            labels=v_labels)\n",
    "        \n",
    "            v_token_prediction = torch.argmax(v_outputs.prediction_logits, axis=-1)\n",
    "\n",
    "                    \n",
    "\n",
    "            v_batch_masks =   [ torch.flatten(bm.nonzero()).tolist()  for bm in v_mask_arr]\n",
    "            \n",
    "            v_masked_token_prediction = [ token[v_batch_masks[t]].tolist() for t,token in enumerate(v_token_prediction) ]\n",
    "            v_masked_token_prediction = list(chain.from_iterable(v_masked_token_prediction))\n",
    "            \n",
    "            v_masked_token_ground_truth   = [ token[v_batch_masks[t]].tolist() for t,token in enumerate(v_labels) ]\n",
    "            v_masked_token_ground_truth = list(chain.from_iterable(v_masked_token_ground_truth))\n",
    "    \n",
    "            \n",
    "            \n",
    "\n",
    "            v_seq_prediction = v_token_prediction.detach().cpu().numpy().flatten()\n",
    "            v_seq_ground_truth = v_labels.detach().cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            # token_prediction = [ token[batch_masks[t]].tolist() for t,token in enumerate(token_prediction) ]\n",
    "            # token_prediction = list(chain.from_iterable(token_prediction))\n",
    "            \n",
    "            # token_ground_truth   = [ token[batch_masks[t]].tolist() for t,token in enumerate(labels) ]\n",
    "            # token_ground_truth = list(chain.from_iterable(token_ground_truth))\n",
    "\n",
    "            \n",
    "            v_instruction_prediction = torch.argmax(v_outputs.seq_relationship_logits, axis=-1)\n",
    "            v_instruction_prediction   = v_instruction_prediction.detach().cpu().numpy().flatten()\n",
    "            v_instruction_ground_truth = v_next_sentence_label.detach().cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "            if N==0:\n",
    "                v_instruction_predictions_all   = v_instruction_prediction\n",
    "                v_instruction_ground_truths_all = v_instruction_ground_truth\n",
    "\n",
    "                v_masked_token_predictions_all   = v_masked_token_prediction\n",
    "                v_masked_token_ground_truths_all = v_masked_token_ground_truth\n",
    "                \n",
    "                v_seq_predictions_all= v_seq_prediction\n",
    "                v_seq_ground_truths_all = v_seq_ground_truth\n",
    "\n",
    "        \n",
    "\n",
    "            else:\n",
    "                v_instruction_predictions_all   = np.concatenate((v_instruction_predictions_all, v_instruction_prediction))\n",
    "                v_instruction_ground_truths_all = np.concatenate((v_instruction_ground_truths_all, v_instruction_ground_truth))\n",
    "\n",
    "                v_masked_token_predictions_all   = np.concatenate((v_masked_token_predictions_all, v_masked_token_prediction ))\n",
    "                v_masked_token_ground_truths_all = np.concatenate((v_masked_token_ground_truths_all, v_masked_token_ground_truth ))\n",
    "                \n",
    "                v_seq_predictions_all =np.concatenate((v_seq_predictions_all, v_seq_prediction ))\n",
    "                v_seq_ground_truths_all =np.concatenate((v_seq_ground_truths_all, v_seq_ground_truth ))\n",
    "                \n",
    "\n",
    "            \n",
    "\n",
    "        v_instruction_accuracy = (accuracy_score(v_instruction_ground_truths_all,v_instruction_predictions_all))\n",
    "        v_instruction_precision, v_instruction_recall, v_instruction_f1, _ = precision_recall_fscore_support(v_instruction_ground_truths_all,v_instruction_predictions_all, average='binary')\n",
    "\n",
    "\n",
    "        v_masked_token_accuracy = (accuracy_score(v_masked_token_ground_truths_all, v_masked_token_predictions_all))\n",
    "        v_masked_token_precision, v_masked_token_recall, v_masked_token_f1, _ = precision_recall_fscore_support(v_masked_token_ground_truths_all,v_masked_token_predictions_all,average='weighted')\n",
    "\n",
    "\n",
    "        v_seq_accuracy = (accuracy_score(v_seq_predictions_all, v_seq_ground_truths_all))\n",
    "        v_seq_precision, v_seq_recall, v_seq_f1, _ = precision_recall_fscore_support(v_seq_ground_truths_all,v_seq_predictions_all,average='weighted')\n",
    "\n",
    "        print(\"Validation: \", \"Instruction F1: \", v_instruction_f1,  \"   v_masked_token_ F1: \",v_masked_token_f1 ,\" V SEQ F1: \", v_seq_f1)\n",
    "        \n",
    "        v_global_instruction_metrices.append(v_instruction_f1)\n",
    "        v_global_masked_token_metrices.append(v_masked_token_f1) \n",
    "\n",
    "    \n",
    "    plot_graph(global_instruction_metrices, v_global_instruction_metrices, 'Next Sentence Prediction Scores')\n",
    "    plot_graph(global_masked_token_metrices, v_global_masked_token_metrices, 'Masked Token Prediction Scores')\n",
    "    # model.save_pretrained(\"./../../models/MLM_CUSTOKEN_UNI.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0,1,2,3,4,5]\n",
    "a[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
