{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a59060-e593-41b3-a4ce-4bb340ef07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os,re\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "from num2words import num2words\n",
    "\n",
    "from trl import SFTTrainer\n",
    "# import torch\n",
    "\n",
    "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "# from torch.distributed.fsdp.wrap import auto_wrap\n",
    "\n",
    "\n",
    "login(token = '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')\n",
    "\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779c65c3-daa0-4075-9c9a-c0eb7ea73af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions Count:  363200 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/home/raisul/ANALYSED_DATA/mlm_x86_O2_d4_single_functions\"\n",
    "\n",
    "json_files = [os.path.join(DATA_PATH, f) for f in os.listdir(DATA_PATH) ]\n",
    "\n",
    "\n",
    "\n",
    "def read_corpus():\n",
    "\n",
    "    all = []\n",
    "\n",
    "    for k, j_file in enumerate(json_files):\n",
    "        # if k>20:\n",
    "        #     break\n",
    "        try:\n",
    "            with open(j_file, 'r') as file:\n",
    "                funct = file.read()\n",
    "                funct = '\\n'.join([line.split('|')[1] for line in funct.split('\\n')[:-1]])\n",
    "                \n",
    "                all.append(funct)\n",
    "        except :\n",
    "            pass\n",
    "    return all\n",
    "    \n",
    "\n",
    "\n",
    "text = read_corpus()\n",
    "\n",
    "\n",
    "def get_training_corpus():\n",
    "    for i in range(0, len(text), 1000):\n",
    "        yield text[i : i + 1000]\n",
    "        \n",
    "# text = text[0:5000]\n",
    "print(\"Functions Count: \",len(text), '\\n')\n",
    "example = text[10]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41fe2949-b651-43ac-b90e-5b10ccae8e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDBR64\n",
      "PUSH R14\n",
      "MOV R14D,EDI\n",
      "PUSH R13\n",
      "NEG R14D\n",
      "PUSH R12\n",
      "CMOVS R14D,EDI\n",
      "PUSH RBP\n",
      "MOV EBP,ESI\n",
      "NEG EBP\n",
      "PUSH RBX\n",
      "CMOVS EBP,ESI\n",
      "TEST EDI,EDI\n",
      "JZ 4795\n",
      "MOV R13D,1\n",
      "LEA R12,[8196]\n",
      "TEST ESI,ESI\n",
      "JZ 4808\n",
      "NOP word ptr [RAX + RAX*1]\n",
      "MOV EBX,1\n",
      "NOP dword ptr [RAX]\n",
      "MOV EDX,EBX\n",
      "MOV RSI,R12\n",
      "MOV EDI,2\n",
      "XOR EAX,EAX\n",
      "CALL 4256\n",
      "ADD EBX,1\n",
      "CMP EBP,EBX\n",
      "JGE 4752\n",
      "MOV EDI,10\n",
      "ADD R13D,1\n",
      "CALL 4224\n",
      "CMP R13D,R14D\n",
      "JLE 4744\n",
      "POP RBX\n",
      "POP RBP\n",
      "POP R12\n",
      "POP R13\n",
      "POP R14\n",
      "RET\n",
      "MOV EDI,10\n",
      "ADD R13D,1\n",
      "CALL 4224\n",
      "CMP R14D,R13D\n",
      "JGE 4808\n",
      "JMP 4795\n"
     ]
    }
   ],
   "source": [
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c0932c-2cde-4148-85b7-0feb9504b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "\n",
    "tokenizer = Tokenizer(models.Unigram())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625a52cb-1c25-40e1-9600-d2f1db2ac56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7986e18-4308-462b-ae63-a6f3aea135d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Regex\n",
    "\n",
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [\n",
    "        normalizers.Replace(\"``\", '\"'),\n",
    "        normalizers.Replace(\"''\", '\"'),\n",
    "        normalizers.NFKD(),\n",
    "        normalizers.StripAccents(),\n",
    "        normalizers.Replace(Regex(\" {2,}\"), \" \"),\n",
    "    ]\n",
    ")\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Metaspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ac41cd-b3ab-4b8c-a000-53885499335d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDBR64\n",
      "PUSH R14\n",
      "MOV R14D,EDI\n",
      "PUSH R13\n",
      "NEG R14D\n",
      "PUSH R12\n",
      "CMOVS R14D,EDI\n",
      "PUSH RBP\n",
      "MOV EBP,ESI\n",
      "NEG EBP\n",
      "PUSH RBX\n",
      "CMOVS EBP,ESI\n",
      "TEST EDI,EDI\n",
      "JZ 4795\n",
      "MOV R13D,1\n",
      "LEA R12,[8196]\n",
      "TEST ESI,ESI\n",
      "JZ 4808\n",
      "NOP word ptr [RAX + RAX*1]\n",
      "MOV EBX,1\n",
      "NOP dword ptr [RAX]\n",
      "MOV EDX,EBX\n",
      "MOV RSI,R12\n",
      "MOV EDI,2\n",
      "XOR EAX,EAX\n",
      "CALL 4256\n",
      "ADD EBX,1\n",
      "CMP EBP,EBX\n",
      "JGE 4752\n",
      "MOV EDI,10\n",
      "ADD R13D,1\n",
      "CALL 4224\n",
      "CMP R13D,R14D\n",
      "JLE 4744\n",
      "POP RBX\n",
      "POP RBP\n",
      "POP R12\n",
      "POP R13\n",
      "POP R14\n",
      "RET\n",
      "MOV EDI,10\n",
      "ADD R13D,1\n",
      "CALL 4224\n",
      "CMP R14D,R13D\n",
      "JGE 4808\n",
      "JMP 4795\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.normalizer.normalize_str(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "144134ac-02c0-49ae-9ea0-d5ae5b40ef1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('▁ENDBR64\\nPUSH', (0, 12)),\n",
       " ('▁R14\\nMOV', (12, 20)),\n",
       " ('▁R14D,EDI\\nPUSH', (20, 34)),\n",
       " ('▁R13\\nNEG', (34, 42)),\n",
       " ('▁R14D\\nPUSH', (42, 52)),\n",
       " ('▁R12\\nCMOVS', (52, 62)),\n",
       " ('▁R14D,EDI\\nPUSH', (62, 76)),\n",
       " ('▁RBP\\nMOV', (76, 84)),\n",
       " ('▁EBP,ESI\\nNEG', (84, 96)),\n",
       " ('▁EBP\\nPUSH', (96, 105)),\n",
       " ('▁RBX\\nCMOVS', (105, 115)),\n",
       " ('▁EBP,ESI\\nTEST', (115, 128)),\n",
       " ('▁EDI,EDI\\nJZ', (128, 139)),\n",
       " ('▁4795\\nMOV', (139, 148)),\n",
       " ('▁R13D,1\\nLEA', (148, 159)),\n",
       " ('▁R12,[8196]\\nTEST', (159, 175)),\n",
       " ('▁ESI,ESI\\nJZ', (175, 186)),\n",
       " ('▁4808\\nNOP', (186, 195)),\n",
       " ('▁word', (195, 200)),\n",
       " ('▁ptr', (200, 204)),\n",
       " ('▁[RAX', (204, 209)),\n",
       " ('▁+', (209, 211)),\n",
       " ('▁RAX*1]\\nMOV', (211, 222)),\n",
       " ('▁EBX,1\\nNOP', (222, 232)),\n",
       " ('▁dword', (232, 238)),\n",
       " ('▁ptr', (238, 242)),\n",
       " ('▁[RAX]\\nMOV', (242, 252)),\n",
       " ('▁EDX,EBX\\nMOV', (252, 264)),\n",
       " ('▁RSI,R12\\nMOV', (264, 276)),\n",
       " ('▁EDI,2\\nXOR', (276, 286)),\n",
       " ('▁EAX,EAX\\nCALL', (286, 299)),\n",
       " ('▁4256\\nADD', (299, 308)),\n",
       " ('▁EBX,1\\nCMP', (308, 318)),\n",
       " ('▁EBP,EBX\\nJGE', (318, 330)),\n",
       " ('▁4752\\nMOV', (330, 339)),\n",
       " ('▁EDI,10\\nADD', (339, 350)),\n",
       " ('▁R13D,1\\nCALL', (350, 362)),\n",
       " ('▁4224\\nCMP', (362, 371)),\n",
       " ('▁R13D,R14D\\nJLE', (371, 385)),\n",
       " ('▁4744\\nPOP', (385, 394)),\n",
       " ('▁RBX\\nPOP', (394, 402)),\n",
       " ('▁RBP\\nPOP', (402, 410)),\n",
       " ('▁R12\\nPOP', (410, 418)),\n",
       " ('▁R13\\nPOP', (418, 426)),\n",
       " ('▁R14\\nRET\\nMOV', (426, 438)),\n",
       " ('▁EDI,10\\nADD', (438, 449)),\n",
       " ('▁R13D,1\\nCALL', (449, 461)),\n",
       " ('▁4224\\nCMP', (461, 470)),\n",
       " ('▁R14D,R13D\\nJGE', (470, 484)),\n",
       " ('▁4808\\nJMP', (484, 493)),\n",
       " ('▁4795', (493, 498))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "472f62d4-c2ad-4ad6-859c-a99348df4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.UnigramTrainer(\n",
    "    vocab_size=25000, special_tokens=special_tokens, unk_token=\"<unk>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da034a8-b62c-4272-a8f0-1189b7e3a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88a13051-7ac1-4541-b069-cf0855d7a021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁ENDBR64\\nPUSH', '▁R14\\nMOV', '▁R14D,EDI\\n', 'PUSH', '▁R13', '\\n', 'N', 'E', 'G', '▁R14', 'D', '\\nPUSH', '▁R12', '\\nC', 'MOV', 'S', '▁R14D,EDI\\n', 'PUSH', '▁RBP\\nMOV', '▁EBP,ESI', '\\n', 'N', 'E', 'G', '▁EBP', '\\nPUSH', '▁RBX\\nC', 'MOV', 'S', '▁EBP,ESI', '\\nT', 'E', 'ST', '▁EDI,EDI\\nJ', 'Z', '▁4795\\nMOV', '▁R13D,1\\n', 'LEA', '▁R12,[8196]\\n', 'T', 'E', 'ST', '▁ESI,ESI\\nJ', 'Z', '▁4808\\n', 'NOP', '▁', 'w', 'o', 'r', 'd', '▁', 'p', 't', 'r', '▁[RAX', '▁', '+', '▁RAX*1]\\nMOV', '▁EBX,1\\nNOP', '▁', 'd', 'w', 'o', 'r', 'd', '▁', 'p', 't', 'r', '▁[RAX]\\nMOV', '▁EDX,EBX\\nMOV', '▁RSI,R12\\nMOV', '▁EDI,2\\nXOR', '▁EAX,EAX\\nC', 'A', 'LL', '▁4256\\nADD', '▁EBX,1\\nC', 'MP', '▁EBP,EBX\\nJG', 'E', '▁4752\\nMOV', '▁EDI,10\\nADD', '▁R13D,1\\nC', 'A', 'LL', '▁4224', '\\nCMP', '▁R13D,R14D\\nJL', 'E', '▁4744', '\\nPOP', '▁RBX', '\\nPOP', '▁RBP', '\\nPOP', '▁R12', '\\nPOP', '▁R13', '\\nPOP', '▁R14\\nRET\\nMOV', '▁EDI,10\\nADD', '▁R13D,1\\nC', 'A', 'LL', '▁4224', '\\nCMP', '▁R14D,R13D\\nJG', 'E', '▁4808\\n', 'J', 'MP', '▁4', '795']\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode(example)\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "808a999b-58e2-4c51-b082-96a7a1925058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=115, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cfaa1ef-67ea-4835-ab95-c0eea6c307b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.special_tokens_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb3f087f-3f61-4f7b-a335-ffe92be7b0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49,\n",
       " 349,\n",
       " 3139,\n",
       " 50,\n",
       " 56,\n",
       " 1358,\n",
       " 111,\n",
       " 21,\n",
       " 175,\n",
       " 64,\n",
       " 33,\n",
       " 29,\n",
       " 47,\n",
       " 545,\n",
       " 27,\n",
       " 52,\n",
       " 3139,\n",
       " 50,\n",
       " 117,\n",
       " 413,\n",
       " 1358,\n",
       " 111,\n",
       " 21,\n",
       " 175,\n",
       " 6046,\n",
       " 29,\n",
       " 628,\n",
       " 27,\n",
       " 52,\n",
       " 413,\n",
       " 94,\n",
       " 21,\n",
       " 26,\n",
       " 285,\n",
       " 17,\n",
       " 12054,\n",
       " 1046,\n",
       " 20,\n",
       " 525,\n",
       " 28,\n",
       " 21,\n",
       " 26,\n",
       " 196,\n",
       " 17,\n",
       " 2901,\n",
       " 68,\n",
       " 6,\n",
       " 12,\n",
       " 11,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 10,\n",
       " 9,\n",
       " 7,\n",
       " 34,\n",
       " 6,\n",
       " 13,\n",
       " 73,\n",
       " 1190,\n",
       " 6,\n",
       " 8,\n",
       " 12,\n",
       " 11,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 10,\n",
       " 9,\n",
       " 7,\n",
       " 80,\n",
       " 240,\n",
       " 118,\n",
       " 43,\n",
       " 30,\n",
       " 14,\n",
       " 15,\n",
       " 811,\n",
       " 180,\n",
       " 22,\n",
       " 1750,\n",
       " 21,\n",
       " 505,\n",
       " 340,\n",
       " 952,\n",
       " 14,\n",
       " 15,\n",
       " 104,\n",
       " 69,\n",
       " 12377,\n",
       " 21,\n",
       " 9555,\n",
       " 19,\n",
       " 46,\n",
       " 19,\n",
       " 35,\n",
       " 19,\n",
       " 47,\n",
       " 19,\n",
       " 56,\n",
       " 19,\n",
       " 743,\n",
       " 340,\n",
       " 952,\n",
       " 14,\n",
       " 15,\n",
       " 104,\n",
       " 69,\n",
       " 9962,\n",
       " 21,\n",
       " 2901,\n",
       " 62,\n",
       " 22,\n",
       " 348,\n",
       " 5709]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "821e59ee-86bc-40b2-b2e0-5857ba597bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4\n"
     ]
    }
   ],
   "source": [
    "cls_token_id = tokenizer.token_to_id(\"[CLS]\")\n",
    "sep_token_id = tokenizer.token_to_id(\"[SEP]\")\n",
    "print(cls_token_id, sep_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "307aa99f-7d78-4c3a-a1ef-a513370d8dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=f\"[CLS]:0 $A:0 [SEP]:0\",\n",
    "    pair=f\"[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1\",\n",
    "    special_tokens=[(\"[CLS]\", cls_token_id), (\"[SEP]\", sep_token_id)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54a48f0c-b963-4208-bdac-1543bedaae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer,\n",
    "    # tokenizer_file=\"tokenizer.json\", # You can load from the tokenizer file, alternatively\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b2328c2-d35a-40f4-808d-234e888c31d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [3, 49, 349, 3139, 50, 56, 1358, 111, 21, 175, 64, 33, 29, 47, 545, 27, 52, 3139, 50, 117, 413, 1358, 111, 21, 175, 6046, 29, 628, 27, 52, 413, 94, 21, 26, 285, 17, 12054, 1046, 20, 525, 28, 21, 26, 196, 17, 2901, 68, 6, 12, 11, 7, 8, 6, 10, 9, 7, 34, 6, 13, 73, 1190, 6, 8, 12, 11, 7, 8, 6, 10, 9, 7, 80, 240, 118, 43, 30, 14, 15, 811, 180, 22, 1750, 21, 505, 340, 952, 14, 15, 104, 69, 12377, 21, 9555, 19, 46, 19, 35, 19, 47, 19, 56, 19, 743, 340, 952, 14, 15, 104, 69, 9962, 21, 2901, 62, 22, 348, 5709, 4], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapped_tokenizer(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4d5a481-a7b4-466d-9517-6870f41a7ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENDBR64\\nPUSH R14\\nMOV R14D,EDI\\nPUSH R13\\nNEG R14D\\nPUSH R12\\nCMOVS R14D,EDI\\nPUSH RBP\\nMOV EBP,ESI\\nNEG EBP\\nPUSH RBX\\nCMOVS EBP,ESI\\nTEST EDI,EDI\\nJZ 4795\\nMOV R13D,1\\nLEA R12,[8196]\\nTEST ESI,ESI\\nJZ 4808\\nNOP word ptr [RAX + RAX*1]\\nMOV EBX,1\\nNOP dword ptr [RAX]\\nMOV EDX,EBX\\nMOV RSI,R12\\nMOV EDI,2\\nXOR EAX,EAX\\nCALL 4256\\nADD EBX,1\\nCMP EBP,EBX\\nJGE 4752\\nMOV EDI,10\\nADD R13D,1\\nCALL 4224\\nCMP R13D,R14D\\nJLE 4744\\nPOP RBX\\nPOP RBP\\nPOP R12\\nPOP R13\\nPOP R14\\nRET\\nMOV EDI,10\\nADD R13D,1\\nCALL 4224\\nCMP R14D,R13D\\nJGE 4808\\nJMP 4795'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e731187-a02c-4c92-a00f-5b7e7a4ed0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./../models/cusTokenizer_UNI/tokenizer_config.json',\n",
       " './../models/cusTokenizer_UNI/special_tokens_map.json',\n",
       " './../models/cusTokenizer_UNI/tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapped_tokenizer.save_pretrained(\"./../models/cusTokenizer_UNI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5eedd-7b7a-44c6-aa8a-044acab0adbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
