{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a59060-e593-41b3-a4ce-4bb340ef07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os,re, json\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "from num2words import num2words\n",
    "\n",
    "from trl import SFTTrainer\n",
    "# import torch\n",
    "\n",
    "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "# from torch.distributed.fsdp.wrap import auto_wrap\n",
    "\n",
    "\n",
    "login(token = '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')\n",
    "\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779c65c3-daa0-4075-9c9a-c0eb7ea73af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "DATA_PATH = '/home/raisul/ANALYSED_DATA/tokenization_data_single_functions'\n",
    "\n",
    "TRAIN_DATA_PATH  ='/home/raisul/ANALYSED_DATA/tokenization_data_single_functions/train/'\n",
    "\n",
    "TEST_DATA_PATH   = '/home/raisul/ANALYSED_DATA/tokenization_data_single_functions/test/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_json_files = [os.path.join(TRAIN_DATA_PATH, f) for f in os.listdir(TRAIN_DATA_PATH) ]\n",
    "\n",
    "test_json_files = [os.path.join(TEST_DATA_PATH, f) for f in os.listdir(TEST_DATA_PATH) ]\n",
    "\n",
    "# disassembly_decimal disassembly_all_number_to_words disassembly_decimal\n",
    "data_key = \"disassembly_decimal\"\n",
    "\n",
    "def read_corpus(json_files):\n",
    "\n",
    "    all = []\n",
    "\n",
    "    for k, j_file in enumerate(json_files):\n",
    "        # if k>20:\n",
    "        #     break\n",
    "        try:\n",
    "\n",
    "            with open(j_file, 'r') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                funct = data[data_key]['input']\n",
    "                \n",
    "                all.append(funct)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    return all\n",
    "    \n",
    "\n",
    "\n",
    "train_text = read_corpus(train_json_files)\n",
    "test_text  = read_corpus(test_json_files)\n",
    "\n",
    "\n",
    "        \n",
    "# text = text[0:5000]\n",
    "print(\"Functions Count: \",len(train_text), '\\n')\n",
    "example = train_text[10]\n",
    "text = train_text + test_text\n",
    "\n",
    "def get_training_corpus():\n",
    "    for i in range(0, len(text), 1000):\n",
    "        yield text[i : i + 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe2949-b651-43ac-b90e-5b10ccae8e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c0932c-2cde-4148-85b7-0feb9504b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "\n",
    "tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "\n",
    "# Pre-tokenizer for splitting at whitespace and punctuation\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Sequence([\n",
    "    pre_tokenizers.Whitespace(),\n",
    "    pre_tokenizers.Punctuation()\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a52cb-1c25-40e1-9600-d2f1db2ac56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7986e18-4308-462b-ae63-a6f3aea135d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [normalizers.NFD(), normalizers.Lowercase(), normalizers.StripAccents()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac41cd-b3ab-4b8c-a000-53885499335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.normalizer.normalize_str(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e80af3-110d-4924-9259-c0b493227eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a6e99b-aafd-485f-91d1-65edc0a1a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee927507-bfb0-4887-bf9f-9eef3128410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144134ac-02c0-49ae-9ea0-d5ae5b40ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe73997-4167-4c2d-856f-c22bd444daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tokenizer = pre_tokenizers.WhitespaceSplit()\n",
    "pre_tokenizer.pre_tokenize_str(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844d6ce-f917-48db-ba2b-f0e65940ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tokenizer = pre_tokenizers.Sequence(\n",
    "    [pre_tokenizers.WhitespaceSplit(), pre_tokenizers.Punctuation()]\n",
    ")\n",
    "pre_tokenizer.pre_tokenize_str(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472f62d4-c2ad-4ad6-859c-a99348df4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(vocab_size=25000, special_tokens=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da034a8-b62c-4272-a8f0-1189b7e3a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a13051-7ac1-4541-b069-cf0855d7a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode(example)\n",
    "print(encoding.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a999b-58e2-4c51-b082-96a7a1925058",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfaa1ef-67ea-4835-ab95-c0eea6c307b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding.special_tokens_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f087f-3f61-4f7b-a335-ffe92be7b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e59ee-86bc-40b2-b2e0-5857ba597bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_token_id = tokenizer.token_to_id(\"[CLS]\")\n",
    "sep_token_id = tokenizer.token_to_id(\"[SEP]\")\n",
    "print(cls_token_id, sep_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307aa99f-7d78-4c3a-a1ef-a513370d8dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=f\"[CLS]:0 $A:0 [SEP]:0\",\n",
    "    pair=f\"[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1\",\n",
    "    special_tokens=[(\"[CLS]\", cls_token_id), (\"[SEP]\", sep_token_id)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a48f0c-b963-4208-bdac-1543bedaae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "wrapped_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer,\n",
    "    # tokenizer_file=\"tokenizer.json\", # You can load from the tokenizer file, alternatively\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2328c2-d35a-40f4-808d-234e888c31d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_tokenizer(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5a481-a7b4-466d-9517-6870f41a7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e731187-a02c-4c92-a00f-5b7e7a4ed0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_tokenizer.save_pretrained(\"./../../models/cusTokenizer_BPE_25k_ASIS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5eedd-7b7a-44c6-aa8a-044acab0adbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
